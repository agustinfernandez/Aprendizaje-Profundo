{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabajo práctico 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmdirHcPShyn"
      },
      "source": [
        "#@title Aprendizaje Profundo | Otoño 2021 by Datitos{display-mode: \"form\" }\n",
        "#@markdown ![71335171.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAACwElEQVR4nOzdMY7iQBBA0WU197/FnJNNJ/FqWvLHZfd7McIGfVVQos3X+/3+A2f7e/UN8EzCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBJfV9/A/7xer6XX3/1/gZ70eU0sEsIiISwSwiIhLBLCIiEsEiP2WEf7m9U9zVnvU9vh85pYJIRFQlgkhEVCWCSERUJYJEbssc5ytL+5at8zec9UM7FICIuEsEgIi4SwSAiLhLBIPGqPdWR1v1VfdwcmFglhkRAWCWGREBYJYZEQFokt9lhHdt4z1UwsEsIiISwSwiIhLBLCIiEsEh/dY+18zq4w7RzlTyYWCWGREBYJYZEQFglhkRAWiS1+jzVhr/Mbd7nP3zCxSAiLhLBICIuEsEgIi4SwSDxqj1U/72r1ulc9l2sCE4uEsEgIi4SwSAiLhLBICIvE7D3W9/fSy6/63dLqdZfvc/F7mMDEIiEsEsIiISwSwiIhLBLCIjF7j3WSs87rTXufyUwsEsIiISwSwiIhLBLCIiEsEq8Ju5N6r3OXc3xP2oeZWCSERUJYJIRFQlgkhEVCWCRG7LGOTN7TfNIdvwcTi4SwSAiLhLBICIuEsEgIi8Toc4U7Pyf9p8n7qiMmFglhkRAWCWGREBYJYZEQFonRe6wjd9zr7MbEIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIi8S8AAP//HtRtH09JwIEAAAAASUVORK5CYII=)\n",
        "#El siguiente notebook fue diseñado por Pablo Marinozi como el primer trabajo práctico correspondiente a la versión de Otoño del 2021 del curso Aprendizaje Profundo organizado por Datitos \n",
        "#Para mayor información consultar https://datitos.github.io/curso-aprendizaje-profundo/#calendario"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVd9DgFBSWXj"
      },
      "source": [
        "# Trabajo Práctico N°3: Overfitting y Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RswOqhTSS73W"
      },
      "source": [
        "Este trabajo práctico tiene 2 partes.\n",
        "\n",
        "La primera parte consiste en un mini tutorial para aprender a usar TensorBoard. Esta herramienta que nos permite visualizar e interpretar el entrenamiento de nuestros modelos a partir de una página web.\n",
        "\n",
        "La segunda parte consiste en verificar de manera práctica la correlación entre la complejidad de un modelo y la presencia de underfitting y overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xLWrwFXFIK"
      },
      "source": [
        "## Parte 1: Tutorial de TensorBoard en Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6yrpzClXnzy"
      },
      "source": [
        "TensorBoard es un kit de herramientas de visualización para la experimentación del aprendizaje automático.\n",
        "\n",
        "TensorBoard permite rastrear y visualizar métricas como las funciones de pérdida y el accuracy, el grafo computacional del modelo, histogramas, imágenes y mucho más.\n",
        "\n",
        "En este tutorial, cubriremos la instalación de TensorBoard,\n",
        "uso básico con PyTorch y cómo visualizar los datos que generamos en la interfaz de usuario de TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmxlSr-_aLoL",
        "outputId": "f0691fbf-57f3-4a9f-e042-920d0615193d"
      },
      "source": [
        "!pip install torch torchvision\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqrXfdI2YGtb"
      },
      "source": [
        "### Summary Writer\n",
        "\n",
        "Los `SummaryWriter` son clases de Tensorboard que se encargan de generar, durante el entrenamiento, los registros necesarios para poder visualizar el progreso del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKvSXcxzYB6H"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fem1nRblYzVV"
      },
      "source": [
        "Por defecto, las instancias de esta clase guardarán todos los registros en la carpeta `./runs/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiRO6wPzZJl6"
      },
      "source": [
        "### Registros de escalares\n",
        "\n",
        "En el aprendizaje automático, es importante comprender métricas clave como la función de pérdida y cómo cambian durante el entrenamiento. `Scalar` ayuda a guardar el valor de la función de pérdida de cada época de entrenamiento. También puede guardar otras métricas como el accuracy.\n",
        "\n",
        "Para registrar un valor escalar, usaremos `add_scalar(etiqueta, scalar_value, global_step = None, walltime = None)`. Por ejemplo, creemos un bucle de entrenamiento para una regresión lineal simple y registremos el valor de la función de pérdida pérdida usando add_scalar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J42PZQ2OZ_Lh"
      },
      "source": [
        "# x = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
        "# y = -5 * x + 0.1 * torch.randn(x.size())\n",
        "\n",
        "# model = torch.nn.Linear(1, 1)\n",
        "# criterion = torch.nn.MSELoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "# def train_model(iter):\n",
        "#     for epoch in range(iter):\n",
        "#         y1 = model(x)\n",
        "#         loss = criterion(y1, y)\n",
        "#         writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "        \n",
        "# train_model(10)\n",
        "# writer.flush()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5-OHcjGaaWT"
      },
      "source": [
        "Llamamos al método `flush()` para asegurarnos de que todos los eventos pendientes se hayan escrito en el disco.\n",
        "\n",
        "Te recomendamos revisar los tutoriales de [torch.utils.tensorboard](https://pytorch.org/docs/stable/tensorboard.html) para encontrar más tipos de visualización de TensorBoard que se puedan registrar.\n",
        "\n",
        "Si ya no necesitamos al `SummaryWriter`, llamemos al método `close()`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRSe6eHcFPyT"
      },
      "source": [
        "# writer.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr9sv-KCa8ZC"
      },
      "source": [
        "### Ejecutar Tensorboard\n",
        "\n",
        "Para visualizar los datos que hemos registrado, debemos instalar TensorBoard a través de la línea de comando. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHbw_QnnFyON",
        "outputId": "42fbb3de-9a40-4a1a-f45f-7d36eb46c74f"
      },
      "source": [
        "!pip install tensorboard"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.36.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (54.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.28.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_1gdoywbk6m"
      },
      "source": [
        "Ahora, iniciaremos TensorBoard, especificando el directorio raíz de los registros que usamos anteriormente. El argumento `logdir` apunta al directorio donde TensorBoard buscará archivos de registros que pueda mostrar. TensorBoard recorrerá de forma recursiva la estructura de directorios enraizada en `logdir`, buscando archivos con extensión `.tfevents`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-qupXpbGH8k"
      },
      "source": [
        "# !tensorboard --logdir=runs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jjdy5txcDZN"
      },
      "source": [
        "Si todo salió bien, al ejecutar la celda anterior obtendremos una dirección url y notaremos que la ejecución no se detiene. Esto es así porque esa celda está publicando una interfaz gráfica interactiva en el puerto local accesible desde esa url. Si estamos trabajando en nuestra máquina local, podremos hacer click sobre el enlace y acceder a una pantalla como esta. <img src=\"https://raw.githubusercontent.com/pytorch/tutorials/master/_static/img/thumbnails/tensorboard_scalars.png\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x80GyOMc2hs"
      },
      "source": [
        "Por el contrario, si estamos trabajando en Google Colab, no podremos acceder a la página que nos muestra el enlace porque apunta a un puerto local (el 6006) de nuestra máquina local, en lugar de al puerto de la máquina virtual que nos provee Google donde está corriendo el servicio. \n",
        "\n",
        "Para solucionar este problema debemos instalar ***ngrok***. Esta herramienta nos permite exponer a internet una URL generada dinámicamente, la cual apunta a un servicio web que se está ejecutando en el localhost de alguna máquina. Esto es justo lo que necesitamos.\n",
        "\n",
        "A continuacion, detenga la celda que está ejecutando TensorBoard y ejecute la siguiente para llevar adelante la instalación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU8ZJXEsS226",
        "outputId": "cd8660c5-63cd-4cd8-d95a-81e2ff6fce46"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-21 16:42:23--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.45.2.52, 3.216.229.131, 34.193.233.154, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.45.2.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13828408 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  56.7MB/s    in 0.2s    \n",
            "\n",
            "2021-04-21 16:42:23 (56.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13828408/13828408]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQQhz165eoI4"
      },
      "source": [
        "Ahora ejecute la siguiente celda que contiene el código necesario para crear el tunel entre el puerto 6006 de la máquina virtual y una url dinámica creada en el momento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvHbH5McTK_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67b2dc1-a165-4ed0-dbe6-b2705c41ea5f"
      },
      "source": [
        "import os\n",
        "LOG_DIR = 'runs'\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://5811442e77dd.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMC7qwowfEp0"
      },
      "source": [
        "Si todo salió bien, en este momento deberíamos poder hacer click en el enlace que arrojó la celda anterior y nos derivará a una página vacía con un mensaje de error que indica que no se pudo conectar al puerto. Esto quiere decir que el tunel fue creado correctamente, pero no hay ningún servicio corriendo en el puerto al que conecta. Para arreglarlo debemos volver a ejecutar la celda que inicia el proceso de tensorboard y volver a ingresar a la url que nos arrojó ngrok.\n",
        "\n",
        "En el caso de que hayas ejecutado la celda y te largue un error en lugar de la url, simplemente vuelve a ejecutarla hasta que funcione."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSzGw3mIguIu"
      },
      "source": [
        "## Parte 2: Complejidad del modelo, overfitting y underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZFP5jExg9UH"
      },
      "source": [
        "A partir de ahora, usted deberá trabajar con código Pytorch para resolver las actividades que le pedimos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRGgEuquhVQu"
      },
      "source": [
        "### Actividad 1\n",
        "\n",
        "Al igual que en TP anterior, trabajaremos con el dataset `fifa2021_training.csv`. En al siguiente celda, usted deberá escribir el código necesario para:\n",
        "\n",
        "1. Cargar el dataset.\n",
        "2. Eliminar todas las columnas excepto: Height, Weight, Age, Sex, Position y todas las features de habilidades.\n",
        "3. Transformar las variable Sex a codificación one-hot\n",
        "4. Separar el dataframe en dos: uno llamado X que contenga todas las features y otro llamado Y que contenga la columna Position (etiqueta)\n",
        "5. Separar ambos dataframes en entrenamiento (70%) y prueba (30%)\n",
        "6. Convertir los 4 dataframes generados en tensores Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0VuQSzeFozi"
      },
      "source": [
        "#Inserte su código aquí"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNYxQ0iNncHi",
        "outputId": "0e831cfc-0ebb-4e07-deaa-30f2db46e00d"
      },
      "source": [
        "#Cargo datos desde Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDc57GwXnote"
      },
      "source": [
        "#Cargo datos con pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/DatitosTP2/fifa2021_training.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIYseBbTqx1p",
        "outputId": "9e97b1b9-4129-4924-e2e2-a187f9dfbef2"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'Name', 'Natinality', 'Overal', 'Potential', 'Height', 'Weight',\n",
              "       'PreferredFoot', 'BirthDate', 'Age', 'PlayerWorkRate', 'WeakFoot',\n",
              "       'SkillMoves', 'Value', 'Wage', 'Club', 'Club_KitNumber',\n",
              "       'Club_JoinedClub', 'Club_ContractLength', 'BallControl', 'Dribbling',\n",
              "       'Marking', 'SlideTackle', 'StandTackle', 'Aggression', 'Reactions',\n",
              "       'Interceptions', 'Vision', 'Composure', 'Crossing', 'ShortPass',\n",
              "       'LongPass', 'Acceleration', 'Stamina', 'Strength', 'Balance',\n",
              "       'SprintSpeed', 'Agility', 'Jumping', 'Heading', 'ShotPower',\n",
              "       'Finishing', 'LongShots', 'Curve', 'FKAcc', 'Penalties', 'Volleys',\n",
              "       'GKDiving', 'GKHandling', 'GKKicking', 'GKReflexes', 'Sex', 'Position'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5hsvmzgrOqN"
      },
      "source": [
        "#Features a borrar\n",
        "#Eliminar todas las columnas excepto: Height, Weight, Age, Sex, Position y todas las features de habilidades.\n",
        "\n",
        "features_to_drop = ['ID',\n",
        "                    'Name',\n",
        "                    'Club',\n",
        "                    'BirthDate',\n",
        "                    'Club_KitNumber',\n",
        "                    'Club_JoinedClub',\n",
        "                    'Club_ContractLength',\n",
        "                    'Natinality',\n",
        "                    'PlayerWorkRate',\n",
        "                    'PreferredFoot'\n",
        "                    ]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "U9vtSHnVrlBK",
        "outputId": "94becfa9-9939-4cc5-f016-b3f2563bf560"
      },
      "source": [
        "#Borro Features\n",
        "\n",
        "df = df.drop(features_to_drop, axis=1)\n",
        "df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Overal</th>\n",
              "      <th>Potential</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Age</th>\n",
              "      <th>WeakFoot</th>\n",
              "      <th>SkillMoves</th>\n",
              "      <th>Value</th>\n",
              "      <th>Wage</th>\n",
              "      <th>BallControl</th>\n",
              "      <th>Dribbling</th>\n",
              "      <th>Marking</th>\n",
              "      <th>SlideTackle</th>\n",
              "      <th>StandTackle</th>\n",
              "      <th>Aggression</th>\n",
              "      <th>Reactions</th>\n",
              "      <th>Interceptions</th>\n",
              "      <th>Vision</th>\n",
              "      <th>Composure</th>\n",
              "      <th>Crossing</th>\n",
              "      <th>ShortPass</th>\n",
              "      <th>LongPass</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Stamina</th>\n",
              "      <th>Strength</th>\n",
              "      <th>Balance</th>\n",
              "      <th>SprintSpeed</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Heading</th>\n",
              "      <th>ShotPower</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>LongShots</th>\n",
              "      <th>Curve</th>\n",
              "      <th>FKAcc</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Volleys</th>\n",
              "      <th>GKDiving</th>\n",
              "      <th>GKHandling</th>\n",
              "      <th>GKKicking</th>\n",
              "      <th>GKReflexes</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>64</td>\n",
              "      <td>73</td>\n",
              "      <td>188</td>\n",
              "      <td>79</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1200000.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>62</td>\n",
              "      <td>55</td>\n",
              "      <td>60</td>\n",
              "      <td>57</td>\n",
              "      <td>60</td>\n",
              "      <td>71</td>\n",
              "      <td>58</td>\n",
              "      <td>60</td>\n",
              "      <td>61</td>\n",
              "      <td>63</td>\n",
              "      <td>44</td>\n",
              "      <td>67</td>\n",
              "      <td>64</td>\n",
              "      <td>54</td>\n",
              "      <td>66</td>\n",
              "      <td>70</td>\n",
              "      <td>54</td>\n",
              "      <td>46</td>\n",
              "      <td>58</td>\n",
              "      <td>57</td>\n",
              "      <td>53</td>\n",
              "      <td>55</td>\n",
              "      <td>39</td>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>33</td>\n",
              "      <td>43</td>\n",
              "      <td>41</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>Male</td>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>70</td>\n",
              "      <td>172</td>\n",
              "      <td>64</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1400000.0</td>\n",
              "      <td>3300.0</td>\n",
              "      <td>66</td>\n",
              "      <td>68</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>37</td>\n",
              "      <td>64</td>\n",
              "      <td>20</td>\n",
              "      <td>58</td>\n",
              "      <td>67</td>\n",
              "      <td>64</td>\n",
              "      <td>62</td>\n",
              "      <td>57</td>\n",
              "      <td>84</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>78</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>42</td>\n",
              "      <td>49</td>\n",
              "      <td>75</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>64</td>\n",
              "      <td>61</td>\n",
              "      <td>65</td>\n",
              "      <td>59</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>Male</td>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68</td>\n",
              "      <td>68</td>\n",
              "      <td>173</td>\n",
              "      <td>70</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1100000.0</td>\n",
              "      <td>3400.0</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>64</td>\n",
              "      <td>74</td>\n",
              "      <td>64</td>\n",
              "      <td>72</td>\n",
              "      <td>54</td>\n",
              "      <td>61</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>56</td>\n",
              "      <td>74</td>\n",
              "      <td>75</td>\n",
              "      <td>64</td>\n",
              "      <td>72</td>\n",
              "      <td>68</td>\n",
              "      <td>66</td>\n",
              "      <td>81</td>\n",
              "      <td>62</td>\n",
              "      <td>68</td>\n",
              "      <td>39</td>\n",
              "      <td>62</td>\n",
              "      <td>58</td>\n",
              "      <td>34</td>\n",
              "      <td>49</td>\n",
              "      <td>46</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>Male</td>\n",
              "      <td>DEF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>70</td>\n",
              "      <td>190</td>\n",
              "      <td>76</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>900000.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>36</td>\n",
              "      <td>31</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>72</td>\n",
              "      <td>55</td>\n",
              "      <td>55</td>\n",
              "      <td>57</td>\n",
              "      <td>36</td>\n",
              "      <td>48</td>\n",
              "      <td>35</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>62</td>\n",
              "      <td>68</td>\n",
              "      <td>70</td>\n",
              "      <td>66</td>\n",
              "      <td>61</td>\n",
              "      <td>53</td>\n",
              "      <td>71</td>\n",
              "      <td>59</td>\n",
              "      <td>43</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>29</td>\n",
              "      <td>48</td>\n",
              "      <td>39</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>Male</td>\n",
              "      <td>DEF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>72</td>\n",
              "      <td>178</td>\n",
              "      <td>68</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1800000.0</td>\n",
              "      <td>6400.0</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>47</td>\n",
              "      <td>43</td>\n",
              "      <td>36</td>\n",
              "      <td>46</td>\n",
              "      <td>59</td>\n",
              "      <td>27</td>\n",
              "      <td>64</td>\n",
              "      <td>53</td>\n",
              "      <td>65</td>\n",
              "      <td>62</td>\n",
              "      <td>65</td>\n",
              "      <td>79</td>\n",
              "      <td>74</td>\n",
              "      <td>44</td>\n",
              "      <td>73</td>\n",
              "      <td>79</td>\n",
              "      <td>78</td>\n",
              "      <td>55</td>\n",
              "      <td>45</td>\n",
              "      <td>57</td>\n",
              "      <td>62</td>\n",
              "      <td>44</td>\n",
              "      <td>56</td>\n",
              "      <td>43</td>\n",
              "      <td>56</td>\n",
              "      <td>53</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>Male</td>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13916</th>\n",
              "      <td>75</td>\n",
              "      <td>76</td>\n",
              "      <td>163</td>\n",
              "      <td>65</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>72</td>\n",
              "      <td>77</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>34</td>\n",
              "      <td>74</td>\n",
              "      <td>20</td>\n",
              "      <td>68</td>\n",
              "      <td>70</td>\n",
              "      <td>61</td>\n",
              "      <td>71</td>\n",
              "      <td>64</td>\n",
              "      <td>93</td>\n",
              "      <td>75</td>\n",
              "      <td>70</td>\n",
              "      <td>95</td>\n",
              "      <td>91</td>\n",
              "      <td>83</td>\n",
              "      <td>68</td>\n",
              "      <td>66</td>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>66</td>\n",
              "      <td>60</td>\n",
              "      <td>32</td>\n",
              "      <td>63</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>Female</td>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13917</th>\n",
              "      <td>82</td>\n",
              "      <td>82</td>\n",
              "      <td>166</td>\n",
              "      <td>57</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>86</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>30</td>\n",
              "      <td>28</td>\n",
              "      <td>44</td>\n",
              "      <td>76</td>\n",
              "      <td>45</td>\n",
              "      <td>78</td>\n",
              "      <td>77</td>\n",
              "      <td>72</td>\n",
              "      <td>77</td>\n",
              "      <td>76</td>\n",
              "      <td>80</td>\n",
              "      <td>71</td>\n",
              "      <td>50</td>\n",
              "      <td>89</td>\n",
              "      <td>74</td>\n",
              "      <td>88</td>\n",
              "      <td>67</td>\n",
              "      <td>62</td>\n",
              "      <td>77</td>\n",
              "      <td>78</td>\n",
              "      <td>76</td>\n",
              "      <td>81</td>\n",
              "      <td>78</td>\n",
              "      <td>76</td>\n",
              "      <td>85</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>Female</td>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13918</th>\n",
              "      <td>76</td>\n",
              "      <td>77</td>\n",
              "      <td>170</td>\n",
              "      <td>56</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>77</td>\n",
              "      <td>73</td>\n",
              "      <td>70</td>\n",
              "      <td>73</td>\n",
              "      <td>72</td>\n",
              "      <td>65</td>\n",
              "      <td>78</td>\n",
              "      <td>74</td>\n",
              "      <td>83</td>\n",
              "      <td>77</td>\n",
              "      <td>80</td>\n",
              "      <td>79</td>\n",
              "      <td>79</td>\n",
              "      <td>78</td>\n",
              "      <td>82</td>\n",
              "      <td>66</td>\n",
              "      <td>87</td>\n",
              "      <td>79</td>\n",
              "      <td>72</td>\n",
              "      <td>73</td>\n",
              "      <td>64</td>\n",
              "      <td>58</td>\n",
              "      <td>59</td>\n",
              "      <td>60</td>\n",
              "      <td>59</td>\n",
              "      <td>55</td>\n",
              "      <td>56</td>\n",
              "      <td>49</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>Female</td>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13919</th>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>180</td>\n",
              "      <td>63</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>77</td>\n",
              "      <td>50</td>\n",
              "      <td>75</td>\n",
              "      <td>79</td>\n",
              "      <td>78</td>\n",
              "      <td>74</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>65</td>\n",
              "      <td>70</td>\n",
              "      <td>50</td>\n",
              "      <td>78</td>\n",
              "      <td>72</td>\n",
              "      <td>77</td>\n",
              "      <td>80</td>\n",
              "      <td>75</td>\n",
              "      <td>77</td>\n",
              "      <td>80</td>\n",
              "      <td>75</td>\n",
              "      <td>77</td>\n",
              "      <td>80</td>\n",
              "      <td>50</td>\n",
              "      <td>46</td>\n",
              "      <td>48</td>\n",
              "      <td>69</td>\n",
              "      <td>67</td>\n",
              "      <td>65</td>\n",
              "      <td>51</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>Female</td>\n",
              "      <td>DEF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13920</th>\n",
              "      <td>92</td>\n",
              "      <td>92</td>\n",
              "      <td>170</td>\n",
              "      <td>60</td>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93</td>\n",
              "      <td>94</td>\n",
              "      <td>46</td>\n",
              "      <td>48</td>\n",
              "      <td>46</td>\n",
              "      <td>67</td>\n",
              "      <td>87</td>\n",
              "      <td>47</td>\n",
              "      <td>92</td>\n",
              "      <td>93</td>\n",
              "      <td>94</td>\n",
              "      <td>93</td>\n",
              "      <td>92</td>\n",
              "      <td>75</td>\n",
              "      <td>70</td>\n",
              "      <td>66</td>\n",
              "      <td>70</td>\n",
              "      <td>73</td>\n",
              "      <td>83</td>\n",
              "      <td>75</td>\n",
              "      <td>76</td>\n",
              "      <td>82</td>\n",
              "      <td>90</td>\n",
              "      <td>88</td>\n",
              "      <td>93</td>\n",
              "      <td>88</td>\n",
              "      <td>90</td>\n",
              "      <td>74</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>Female</td>\n",
              "      <td>FWD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13921 rows × 43 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Overal  Potential  Height  ...  GKReflexes     Sex  Position\n",
              "0          64         73     188  ...          12    Male       MID\n",
              "1          67         70     172  ...          15    Male       MID\n",
              "2          68         68     173  ...          16    Male       DEF\n",
              "3          63         70     190  ...           6    Male       DEF\n",
              "4          69         72     178  ...          15    Male       MID\n",
              "...       ...        ...     ...  ...         ...     ...       ...\n",
              "13916      75         76     163  ...          14  Female       MID\n",
              "13917      82         82     166  ...          12  Female       MID\n",
              "13918      76         77     170  ...          11  Female       MID\n",
              "13919      77         77     180  ...          17  Female       DEF\n",
              "13920      92         92     170  ...          11  Female       FWD\n",
              "\n",
              "[13921 rows x 43 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM_3yQUA2BvY"
      },
      "source": [
        "#Estandarizamos valores numéricos\n",
        "numeric_features = df.dtypes[df.dtypes != 'object'].index\n",
        "df[numeric_features].isna().sum()\n",
        "\n",
        "df[numeric_features] = df[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
        "df[numeric_features] = df[numeric_features].fillna(df[numeric_features].mean())\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "dTcD3PbEYYY9",
        "outputId": "99df6044-e6b8-4a6b-f7ce-ff8fdc1413dd"
      },
      "source": [
        " #Transformar las variable Sex a codificación one-hot\n",
        "\n",
        "one_hot = pd.get_dummies(df['Sex'])\n",
        "df_1 = df.drop('Sex',axis = 1)\n",
        "df_1 = df_1.join(one_hot)\n",
        "df_1  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Overal</th>\n",
              "      <th>Potential</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Age</th>\n",
              "      <th>WeakFoot</th>\n",
              "      <th>SkillMoves</th>\n",
              "      <th>Value</th>\n",
              "      <th>Wage</th>\n",
              "      <th>BallControl</th>\n",
              "      <th>Dribbling</th>\n",
              "      <th>Marking</th>\n",
              "      <th>SlideTackle</th>\n",
              "      <th>StandTackle</th>\n",
              "      <th>Aggression</th>\n",
              "      <th>Reactions</th>\n",
              "      <th>Interceptions</th>\n",
              "      <th>Vision</th>\n",
              "      <th>Composure</th>\n",
              "      <th>Crossing</th>\n",
              "      <th>ShortPass</th>\n",
              "      <th>LongPass</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Stamina</th>\n",
              "      <th>Strength</th>\n",
              "      <th>Balance</th>\n",
              "      <th>SprintSpeed</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Heading</th>\n",
              "      <th>ShotPower</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>LongShots</th>\n",
              "      <th>Curve</th>\n",
              "      <th>FKAcc</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Volleys</th>\n",
              "      <th>GKDiving</th>\n",
              "      <th>GKHandling</th>\n",
              "      <th>GKKicking</th>\n",
              "      <th>GKReflexes</th>\n",
              "      <th>Position</th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.340843</td>\n",
              "      <td>0.214830</td>\n",
              "      <td>0.976994</td>\n",
              "      <td>0.561400</td>\n",
              "      <td>-0.775523</td>\n",
              "      <td>0.053709</td>\n",
              "      <td>-0.495949</td>\n",
              "      <td>-2.623934e-01</td>\n",
              "      <td>-4.053618e-01</td>\n",
              "      <td>0.160974</td>\n",
              "      <td>-0.071411</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.508629</td>\n",
              "      <td>0.534847</td>\n",
              "      <td>0.858520</td>\n",
              "      <td>-0.471837</td>\n",
              "      <td>0.611080</td>\n",
              "      <td>0.445511</td>\n",
              "      <td>0.316353</td>\n",
              "      <td>-0.345367</td>\n",
              "      <td>0.497698</td>\n",
              "      <td>0.663176</td>\n",
              "      <td>-0.721312</td>\n",
              "      <td>0.176912</td>\n",
              "      <td>0.397796</td>\n",
              "      <td>-0.729773</td>\n",
              "      <td>-1.292021</td>\n",
              "      <td>-0.394032</td>\n",
              "      <td>-0.666230</td>\n",
              "      <td>0.032206</td>\n",
              "      <td>-0.273811</td>\n",
              "      <td>-0.376499</td>\n",
              "      <td>-0.232084</td>\n",
              "      <td>-0.487699</td>\n",
              "      <td>-0.572612</td>\n",
              "      <td>-0.351257</td>\n",
              "      <td>-0.127573</td>\n",
              "      <td>-0.201908</td>\n",
              "      <td>-0.370463</td>\n",
              "      <td>-0.193790</td>\n",
              "      <td>-0.259796</td>\n",
              "      <td>MID</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.061197</td>\n",
              "      <td>-0.246904</td>\n",
              "      <td>-1.283602</td>\n",
              "      <td>-1.479809</td>\n",
              "      <td>-0.144249</td>\n",
              "      <td>0.053709</td>\n",
              "      <td>0.765074</td>\n",
              "      <td>-2.430284e-01</td>\n",
              "      <td>-3.325743e-01</td>\n",
              "      <td>0.397072</td>\n",
              "      <td>0.609450</td>\n",
              "      <td>-0.689617</td>\n",
              "      <td>-0.574237</td>\n",
              "      <td>-0.708320</td>\n",
              "      <td>-1.111688</td>\n",
              "      <td>0.151523</td>\n",
              "      <td>-1.288012</td>\n",
              "      <td>0.232227</td>\n",
              "      <td>0.636908</td>\n",
              "      <td>0.737787</td>\n",
              "      <td>0.160136</td>\n",
              "      <td>0.207856</td>\n",
              "      <td>1.282676</td>\n",
              "      <td>0.113341</td>\n",
              "      <td>-0.652468</td>\n",
              "      <td>0.977339</td>\n",
              "      <td>1.029354</td>\n",
              "      <td>1.116696</td>\n",
              "      <td>-1.957092</td>\n",
              "      <td>-0.194370</td>\n",
              "      <td>1.217970</td>\n",
              "      <td>0.672828</td>\n",
              "      <td>1.089489</td>\n",
              "      <td>0.857092</td>\n",
              "      <td>1.019652</td>\n",
              "      <td>1.024686</td>\n",
              "      <td>0.864546</td>\n",
              "      <td>-0.257530</td>\n",
              "      <td>-0.428500</td>\n",
              "      <td>-0.607165</td>\n",
              "      <td>-0.095985</td>\n",
              "      <td>MID</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.195210</td>\n",
              "      <td>-0.554726</td>\n",
              "      <td>-1.142315</td>\n",
              "      <td>-0.663326</td>\n",
              "      <td>0.487026</td>\n",
              "      <td>-1.421017</td>\n",
              "      <td>-0.495949</td>\n",
              "      <td>-2.720759e-01</td>\n",
              "      <td>-3.285305e-01</td>\n",
              "      <td>0.160974</td>\n",
              "      <td>0.347581</td>\n",
              "      <td>0.722379</td>\n",
              "      <td>0.791116</td>\n",
              "      <td>0.719020</td>\n",
              "      <td>1.032361</td>\n",
              "      <td>0.151523</td>\n",
              "      <td>1.180807</td>\n",
              "      <td>-0.052153</td>\n",
              "      <td>0.156075</td>\n",
              "      <td>0.629472</td>\n",
              "      <td>0.227649</td>\n",
              "      <td>0.142810</td>\n",
              "      <td>0.614680</td>\n",
              "      <td>0.749047</td>\n",
              "      <td>-0.086941</td>\n",
              "      <td>0.550561</td>\n",
              "      <td>0.210046</td>\n",
              "      <td>0.155324</td>\n",
              "      <td>1.399150</td>\n",
              "      <td>0.542001</td>\n",
              "      <td>0.695847</td>\n",
              "      <td>-0.376499</td>\n",
              "      <td>0.733681</td>\n",
              "      <td>0.534342</td>\n",
              "      <td>-0.515745</td>\n",
              "      <td>0.024000</td>\n",
              "      <td>0.148015</td>\n",
              "      <td>-0.090663</td>\n",
              "      <td>-0.602611</td>\n",
              "      <td>-0.075682</td>\n",
              "      <td>-0.041381</td>\n",
              "      <td>DEF</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.474856</td>\n",
              "      <td>-0.246904</td>\n",
              "      <td>1.259569</td>\n",
              "      <td>0.153158</td>\n",
              "      <td>-0.775523</td>\n",
              "      <td>0.053709</td>\n",
              "      <td>-0.495949</td>\n",
              "      <td>-2.914408e-01</td>\n",
              "      <td>-3.932305e-01</td>\n",
              "      <td>-1.373662</td>\n",
              "      <td>-1.328385</td>\n",
              "      <td>1.063205</td>\n",
              "      <td>1.026522</td>\n",
              "      <td>1.087366</td>\n",
              "      <td>-0.068637</td>\n",
              "      <td>-0.783517</td>\n",
              "      <td>0.468648</td>\n",
              "      <td>-1.331861</td>\n",
              "      <td>-0.885729</td>\n",
              "      <td>-0.832786</td>\n",
              "      <td>-0.717524</td>\n",
              "      <td>-0.377556</td>\n",
              "      <td>-0.186915</td>\n",
              "      <td>0.304053</td>\n",
              "      <td>0.397796</td>\n",
              "      <td>0.123783</td>\n",
              "      <td>-0.267885</td>\n",
              "      <td>-0.737379</td>\n",
              "      <td>0.538575</td>\n",
              "      <td>0.372069</td>\n",
              "      <td>-1.168880</td>\n",
              "      <td>-0.926146</td>\n",
              "      <td>-0.943700</td>\n",
              "      <td>-1.240782</td>\n",
              "      <td>-0.800078</td>\n",
              "      <td>-0.038543</td>\n",
              "      <td>-0.237809</td>\n",
              "      <td>-0.424396</td>\n",
              "      <td>-0.254389</td>\n",
              "      <td>-0.311897</td>\n",
              "      <td>-0.587417</td>\n",
              "      <td>DEF</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.329223</td>\n",
              "      <td>0.060919</td>\n",
              "      <td>-0.435879</td>\n",
              "      <td>-0.935487</td>\n",
              "      <td>-0.144249</td>\n",
              "      <td>0.053709</td>\n",
              "      <td>0.765074</td>\n",
              "      <td>-2.042985e-01</td>\n",
              "      <td>-2.072180e-01</td>\n",
              "      <td>0.574146</td>\n",
              "      <td>0.871320</td>\n",
              "      <td>-0.007964</td>\n",
              "      <td>-0.150507</td>\n",
              "      <td>-0.570191</td>\n",
              "      <td>-0.590162</td>\n",
              "      <td>-0.367944</td>\n",
              "      <td>-0.955671</td>\n",
              "      <td>0.658796</td>\n",
              "      <td>-0.485035</td>\n",
              "      <td>0.791945</td>\n",
              "      <td>0.160136</td>\n",
              "      <td>0.728222</td>\n",
              "      <td>0.948678</td>\n",
              "      <td>0.685477</td>\n",
              "      <td>-1.702733</td>\n",
              "      <td>0.621691</td>\n",
              "      <td>0.961079</td>\n",
              "      <td>0.979357</td>\n",
              "      <td>-0.838345</td>\n",
              "      <td>-0.420946</td>\n",
              "      <td>-0.124633</td>\n",
              "      <td>0.772764</td>\n",
              "      <td>-0.181254</td>\n",
              "      <td>0.426759</td>\n",
              "      <td>-0.003946</td>\n",
              "      <td>0.461800</td>\n",
              "      <td>0.533839</td>\n",
              "      <td>-0.480019</td>\n",
              "      <td>-0.312426</td>\n",
              "      <td>-0.370951</td>\n",
              "      <td>-0.095985</td>\n",
              "      <td>MID</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13916</th>\n",
              "      <td>1.133302</td>\n",
              "      <td>0.676564</td>\n",
              "      <td>-2.555188</td>\n",
              "      <td>-1.343729</td>\n",
              "      <td>0.066176</td>\n",
              "      <td>0.053709</td>\n",
              "      <td>0.765074</td>\n",
              "      <td>-1.624752e-16</td>\n",
              "      <td>-1.113967e-16</td>\n",
              "      <td>0.751219</td>\n",
              "      <td>1.080816</td>\n",
              "      <td>-1.614718</td>\n",
              "      <td>-1.374617</td>\n",
              "      <td>-1.537098</td>\n",
              "      <td>-1.285530</td>\n",
              "      <td>1.190456</td>\n",
              "      <td>-1.288012</td>\n",
              "      <td>0.943176</td>\n",
              "      <td>0.877325</td>\n",
              "      <td>0.575314</td>\n",
              "      <td>0.767748</td>\n",
              "      <td>0.663176</td>\n",
              "      <td>1.883873</td>\n",
              "      <td>0.749047</td>\n",
              "      <td>0.397796</td>\n",
              "      <td>2.186543</td>\n",
              "      <td>1.780387</td>\n",
              "      <td>1.322705</td>\n",
              "      <td>0.280402</td>\n",
              "      <td>0.768577</td>\n",
              "      <td>0.845025</td>\n",
              "      <td>1.222476</td>\n",
              "      <td>0.937000</td>\n",
              "      <td>0.641925</td>\n",
              "      <td>-0.629478</td>\n",
              "      <td>0.899600</td>\n",
              "      <td>0.754310</td>\n",
              "      <td>-0.424396</td>\n",
              "      <td>-0.544574</td>\n",
              "      <td>0.042425</td>\n",
              "      <td>-0.150588</td>\n",
              "      <td>MID</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13917</th>\n",
              "      <td>2.071394</td>\n",
              "      <td>1.600031</td>\n",
              "      <td>-2.131326</td>\n",
              "      <td>-2.432374</td>\n",
              "      <td>1.118300</td>\n",
              "      <td>1.528436</td>\n",
              "      <td>2.026097</td>\n",
              "      <td>-1.624752e-16</td>\n",
              "      <td>-1.113967e-16</td>\n",
              "      <td>1.577562</td>\n",
              "      <td>1.709303</td>\n",
              "      <td>0.917137</td>\n",
              "      <td>-0.762562</td>\n",
              "      <td>-0.938536</td>\n",
              "      <td>-0.706057</td>\n",
              "      <td>1.398243</td>\n",
              "      <td>-0.101080</td>\n",
              "      <td>1.654125</td>\n",
              "      <td>1.438296</td>\n",
              "      <td>1.171049</td>\n",
              "      <td>1.172822</td>\n",
              "      <td>1.443725</td>\n",
              "      <td>1.015478</td>\n",
              "      <td>0.494765</td>\n",
              "      <td>-1.217996</td>\n",
              "      <td>1.759766</td>\n",
              "      <td>0.619700</td>\n",
              "      <td>1.666052</td>\n",
              "      <td>0.194345</td>\n",
              "      <td>0.542001</td>\n",
              "      <td>1.367148</td>\n",
              "      <td>1.572252</td>\n",
              "      <td>1.445298</td>\n",
              "      <td>1.771550</td>\n",
              "      <td>1.986384</td>\n",
              "      <td>1.712658</td>\n",
              "      <td>2.297606</td>\n",
              "      <td>-0.257530</td>\n",
              "      <td>-0.254389</td>\n",
              "      <td>-0.548112</td>\n",
              "      <td>-0.259796</td>\n",
              "      <td>MID</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13918</th>\n",
              "      <td>1.267315</td>\n",
              "      <td>0.830475</td>\n",
              "      <td>-1.566177</td>\n",
              "      <td>-2.568454</td>\n",
              "      <td>0.066176</td>\n",
              "      <td>0.053709</td>\n",
              "      <td>2.026097</td>\n",
              "      <td>-1.624752e-16</td>\n",
              "      <td>-1.113967e-16</td>\n",
              "      <td>1.046342</td>\n",
              "      <td>0.871320</td>\n",
              "      <td>1.111895</td>\n",
              "      <td>1.261928</td>\n",
              "      <td>1.087366</td>\n",
              "      <td>0.510836</td>\n",
              "      <td>1.606029</td>\n",
              "      <td>1.275762</td>\n",
              "      <td>2.009600</td>\n",
              "      <td>1.438296</td>\n",
              "      <td>1.604311</td>\n",
              "      <td>1.307846</td>\n",
              "      <td>1.638862</td>\n",
              "      <td>0.881879</td>\n",
              "      <td>1.194041</td>\n",
              "      <td>0.074638</td>\n",
              "      <td>1.617506</td>\n",
              "      <td>0.961079</td>\n",
              "      <td>0.567341</td>\n",
              "      <td>0.710690</td>\n",
              "      <td>0.655289</td>\n",
              "      <td>-0.050044</td>\n",
              "      <td>0.622861</td>\n",
              "      <td>0.632022</td>\n",
              "      <td>0.588134</td>\n",
              "      <td>0.678453</td>\n",
              "      <td>0.461800</td>\n",
              "      <td>0.313368</td>\n",
              "      <td>-0.146285</td>\n",
              "      <td>-0.428500</td>\n",
              "      <td>-0.430004</td>\n",
              "      <td>-0.314399</td>\n",
              "      <td>MID</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13919</th>\n",
              "      <td>1.401328</td>\n",
              "      <td>0.830475</td>\n",
              "      <td>-0.153304</td>\n",
              "      <td>-1.615890</td>\n",
              "      <td>0.697451</td>\n",
              "      <td>0.053709</td>\n",
              "      <td>-0.495949</td>\n",
              "      <td>-1.624752e-16</td>\n",
              "      <td>-1.113967e-16</td>\n",
              "      <td>1.046342</td>\n",
              "      <td>-0.333281</td>\n",
              "      <td>1.355342</td>\n",
              "      <td>1.544415</td>\n",
              "      <td>1.363625</td>\n",
              "      <td>1.032361</td>\n",
              "      <td>1.502136</td>\n",
              "      <td>1.513148</td>\n",
              "      <td>0.729891</td>\n",
              "      <td>0.877325</td>\n",
              "      <td>-0.020421</td>\n",
              "      <td>1.240334</td>\n",
              "      <td>1.183542</td>\n",
              "      <td>0.815079</td>\n",
              "      <td>1.066900</td>\n",
              "      <td>0.801744</td>\n",
              "      <td>0.906210</td>\n",
              "      <td>1.029354</td>\n",
              "      <td>0.773349</td>\n",
              "      <td>1.054920</td>\n",
              "      <td>1.561592</td>\n",
              "      <td>-0.646756</td>\n",
              "      <td>-0.026723</td>\n",
              "      <td>0.022065</td>\n",
              "      <td>1.126050</td>\n",
              "      <td>1.360852</td>\n",
              "      <td>1.024686</td>\n",
              "      <td>0.423604</td>\n",
              "      <td>-0.035041</td>\n",
              "      <td>-0.370463</td>\n",
              "      <td>-0.489058</td>\n",
              "      <td>0.013222</td>\n",
              "      <td>DEF</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13920</th>\n",
              "      <td>3.411526</td>\n",
              "      <td>3.139143</td>\n",
              "      <td>-1.566177</td>\n",
              "      <td>-2.024132</td>\n",
              "      <td>1.959999</td>\n",
              "      <td>1.528436</td>\n",
              "      <td>2.026097</td>\n",
              "      <td>-1.624752e-16</td>\n",
              "      <td>-1.113967e-16</td>\n",
              "      <td>1.990734</td>\n",
              "      <td>1.971173</td>\n",
              "      <td>-0.056653</td>\n",
              "      <td>0.084899</td>\n",
              "      <td>-0.109758</td>\n",
              "      <td>0.626731</td>\n",
              "      <td>2.541069</td>\n",
              "      <td>-0.006125</td>\n",
              "      <td>2.649454</td>\n",
              "      <td>2.720517</td>\n",
              "      <td>2.362518</td>\n",
              "      <td>2.253019</td>\n",
              "      <td>2.484456</td>\n",
              "      <td>0.681480</td>\n",
              "      <td>0.431194</td>\n",
              "      <td>0.074638</td>\n",
              "      <td>0.408302</td>\n",
              "      <td>0.551424</td>\n",
              "      <td>1.322705</td>\n",
              "      <td>0.882805</td>\n",
              "      <td>1.335016</td>\n",
              "      <td>1.740094</td>\n",
              "      <td>2.171867</td>\n",
              "      <td>2.055255</td>\n",
              "      <td>2.417050</td>\n",
              "      <td>2.555050</td>\n",
              "      <td>2.588258</td>\n",
              "      <td>1.691311</td>\n",
              "      <td>-0.090663</td>\n",
              "      <td>-0.254389</td>\n",
              "      <td>-0.134736</td>\n",
              "      <td>-0.314399</td>\n",
              "      <td>FWD</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13921 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Overal  Potential    Height  ...  Position  Female  Male\n",
              "0     -0.340843   0.214830  0.976994  ...       MID       0     1\n",
              "1      0.061197  -0.246904 -1.283602  ...       MID       0     1\n",
              "2      0.195210  -0.554726 -1.142315  ...       DEF       0     1\n",
              "3     -0.474856  -0.246904  1.259569  ...       DEF       0     1\n",
              "4      0.329223   0.060919 -0.435879  ...       MID       0     1\n",
              "...         ...        ...       ...  ...       ...     ...   ...\n",
              "13916  1.133302   0.676564 -2.555188  ...       MID       1     0\n",
              "13917  2.071394   1.600031 -2.131326  ...       MID       1     0\n",
              "13918  1.267315   0.830475 -1.566177  ...       MID       1     0\n",
              "13919  1.401328   0.830475 -0.153304  ...       DEF       1     0\n",
              "13920  3.411526   3.139143 -1.566177  ...       FWD       1     0\n",
              "\n",
              "[13921 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OB49hL-1ccml",
        "outputId": "e6cb2142-2988-4fe5-c336-3f16e79d17cb"
      },
      "source": [
        "#Separar el dataframe en dos: uno llamado X que contenga todas las features y otro llamado Y que contenga la columna Position (etiqueta)\n",
        "\n",
        "Y = df_1[['Position']]\n",
        "X  = df_1.drop('Position',axis = 1)\n",
        "Y\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DEF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DEF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13916</th>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13917</th>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13918</th>\n",
              "      <td>MID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13919</th>\n",
              "      <td>DEF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13920</th>\n",
              "      <td>FWD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13921 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Position\n",
              "0          MID\n",
              "1          MID\n",
              "2          DEF\n",
              "3          DEF\n",
              "4          MID\n",
              "...        ...\n",
              "13916      MID\n",
              "13917      MID\n",
              "13918      MID\n",
              "13919      DEF\n",
              "13920      FWD\n",
              "\n",
              "[13921 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_7fiiJI88CO",
        "outputId": "28d31c58-1bd0-4eba-e5d2-f8d801e8581d"
      },
      "source": [
        "#Convierto predicción a un núúmero\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "transformador_etiquetas = LabelEncoder()\n",
        "\n",
        "transformador_etiquetas.fit(Y)\n",
        "\n",
        "Y = transformador_etiquetas.transform(Y)\n",
        "Y\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 0, ..., 3, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS8y_JIyceJE"
      },
      "source": [
        "#Separar ambos dataframes en entrenamiento (70%) y prueba (30%)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, train_size=0.70, random_state=42)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRfMLrgBfaGz"
      },
      "source": [
        "#Convertir los 4 dataframes generados en tensores Pytorch\n",
        "\n",
        "n_train1 = X_train.shape[0]\n",
        "n_train2 = X_test.shape[0]\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbBjWEM8-BmG"
      },
      "source": [
        "X_train = torch.tensor(X_train[:n_train1].values, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test[:n_train2].values, dtype=torch.float32)\n",
        "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
        "Y_test = torch.tensor(Y_test,dtype=torch.long)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxAGJt0HCF8V",
        "outputId": "310ca59b-ef77-443b-b3d6-9cad91e560ba"
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 3, 2,  ..., 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kazIDwjWjT8S"
      },
      "source": [
        "### Actividad 2\n",
        "\n",
        "Implementar 3 MLP con dos capas oculta y una capa de salida que permita clasificar a los jugadores entre las cuatro posiciones disponibles. Estos modelos deberán llamarse:\n",
        "\n",
        "1. `modelo_chico`: tiene 4 neuronas en cada capa oculta.\n",
        "2. `modelo_medio`: tiene 16 neuronas en cada capa oculta.\n",
        "3. `modelo_grande`: tiene 256 neuronas en cada capa oculta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF0AsSWFHyJW"
      },
      "source": [
        "In_features = X_train.shape[1]\n",
        "out_features = 4 #'DEF', 'FWD', 'GK', 'MID'\n",
        "import torch.nn as nn"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikIRjny8Kb8d"
      },
      "source": [
        "modelo_chico = nn.Sequential(nn.Linear(In_features,4),\n",
        "                             nn.Linear(4,4),nn.ReLU(),\n",
        "                             nn.Linear(4,4),nn.ReLU(),\n",
        "                             nn.Linear(4,out_features))\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L20SPkMKIS4E"
      },
      "source": [
        "modelo_medio = nn.Sequential(nn.Linear(In_features,16),\n",
        "                             nn.Linear(16,16),nn.ReLU(),\n",
        "                             nn.Linear(16,16),nn.ReLU(),\n",
        "                             nn.Linear(16,out_features))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykQ5dHITITLs"
      },
      "source": [
        "modelo_grande = nn.Sequential(nn.Linear(In_features,256),\n",
        "                             nn.Linear(256,256),nn.ReLU(),\n",
        "                             nn.Linear(256,256),nn.ReLU(),\n",
        "                             nn.Linear(256,out_features))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI_W_fQKkdcN"
      },
      "source": [
        "### Actividad 3\n",
        "\n",
        "Leer detalladamente el código provisto para cada una de las siguientes funciones y entender su comportamiento. En la siguiente actividad deberá utilizarlas así que preste atención a todos los detalles. \n",
        "\n",
        "Funciones:\n",
        "\n",
        "* `load_array`: devuelve un iterador para obtener los batchs de un dataset\n",
        "  * `data_arrays`: tensor o tupla de tensores que contiene el dataset\n",
        "  * `batch_size`: tamaño de batch\n",
        "* `evaluate_loss`: devuelve la función de pérdida calculada para un batch\n",
        "  * `net`: modelo\n",
        "  * `data_iter`: iterador sobre el batch\n",
        "  * `loss`: función de pérdida a calcular\n",
        "* `accuracy`: devuelve la cantidad de elementos que se predijeron correctamente\n",
        "  * `y_hat`: predicciones\n",
        "  * `y`: etiquetas\n",
        "* `train_epoch_ch3`: entrena una epoch y devuelve la función de pérdida y el accuracy sobre el dataset completo\n",
        "  * `net`: modelo\n",
        "  * `train_iter`: iterador sobre el datset de entrenamiento completo\n",
        "  * `loss`: función de pérdida\n",
        "  * `updater`: algoritmo de optimización\n",
        "\n",
        "Clases:\n",
        "\n",
        "* `Accumulator`: objeto que almacena sumas sobre varias variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETh2fZJ6M4kl"
      },
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True): \n",
        "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
        "    dataset = data.TensorDataset(*data_arrays)\n",
        "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka42OFilSFQt"
      },
      "source": [
        "class Accumulator:  \n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yDSxKLPR4oK"
      },
      "source": [
        "def evaluate_loss(net, data_iter, loss):  \n",
        "    \"\"\"Evaluate the loss of a model on the given dataset.\"\"\"\n",
        "    metric = Accumulator(2)  # Sum of losses, no. of examples\n",
        "    for X, y in data_iter:\n",
        "        out = net(X)\n",
        "        print(y)\n",
        "        print(torch.max(y, 1))\n",
        "        y = torch.max(y, 1)[1]\n",
        "        l = loss(out, y)\n",
        "        metric.add(l.sum(), l.numel())\n",
        "    return metric[0] / metric[1]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI4O8zKFPX1p"
      },
      "source": [
        "from torch.utils import data\n",
        "batch_size = 32\n",
        "data_iter_train = load_array((X_train,Y_train), batch_size)\n",
        "data_iter_test = load_array((X_test,Y_test), batch_size)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1pfzHPQVE4U"
      },
      "source": [
        "def accuracy(y_hat, y):  \n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)\n",
        "    cmp = y_hat.type(y.dtype) == y\n",
        "    return float(cmp.type(y.dtype).sum())\n",
        "\n",
        "    \n",
        "def evaluate_accuracy(net, data_iter, loss):\n",
        "    \"\"\"Compute the accuracy for a model on a dataset.\"\"\"\n",
        "    if isinstance(net, torch.nn.Module):\n",
        "        net.eval()  # Set the model to evaluation mode\n",
        "    metric = Accumulator(3)  # No. of correct predictions, loss, no. of predictions\n",
        "    for X, y in data_iter:\n",
        "        l = loss(net(X), y)\n",
        "        metric.add(accuracy(net(X), y), l.sum(), y.numel())\n",
        "    acc = metric[0] / metric[2]\n",
        "    loss = metric[1]\n",
        "    return acc, loss\n",
        "\n",
        "def train_epoch_ch3(net, train_iter, loss, updater):  \n",
        "    \"\"\"The training loop defined in Chapter 3.\"\"\"\n",
        "    # Set the model to training mode\n",
        "    if isinstance(net, torch.nn.Module):\n",
        "        net.train()\n",
        "    # Sum of training loss, sum of training accuracy, no. of examples\n",
        "    metric = Accumulator(3)\n",
        "    for X, y in train_iter:\n",
        "        # Compute gradients and update parameters\n",
        "        y_hat = net(X)\n",
        "        y = torch.max(y, 1)[1]\n",
        "        l = loss(y_hat, y)\n",
        "        if isinstance(updater, torch.optim.Optimizer):\n",
        "            # Using PyTorch in-built optimizer & loss criterion\n",
        "            updater.zero_grad()\n",
        "            l.backward()\n",
        "            updater.step()\n",
        "            metric.add(float(l) * len(y), accuracy(y_hat, y), y.numel())\n",
        "        else:\n",
        "            # Using custom built optimizer & loss criterion\n",
        "            l.sum().backward()\n",
        "            updater(X.shape[0])\n",
        "            metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
        "    # Return training loss and training accuracy\n",
        "    return metric[0] / metric[2], metric[1] / metric[2]\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzASpZI7pRpC"
      },
      "source": [
        "### Actividad 4\n",
        "\n",
        "Implementar la función `train()` que reciba los siguientes parámetros:\n",
        "\n",
        "* `net`: modelo a entrenar\n",
        "* `train_iter`: iterador sobre el dataset de entrenamiento completo\n",
        "* `test_iter`: iterador sobre el dataset de prueba completo\n",
        "* `writer`: instancia de `SummaryWriter` encargada de crear los registros para TensorBoard\n",
        "* `name`: string que contiene el nombre del modelo a entrenar para mostrar en TensorBoard\n",
        "* `num_epochs`: cantidad de épocas de entrenamiento\n",
        "\n",
        "Esta función debe llevar adelante las siguientes tareas:\n",
        "\n",
        "* entrenar el modelo 500 épocas\n",
        "* registrar con el SummaryWriter para cada época:\n",
        "  * valor de la función de pérdida sobre el conjunto de entrenamiento\n",
        "  * valor de la función de pérdida sobre el conjunto de prueba\n",
        "  * accuracy sobre el conjunto de entrenamiento\n",
        "  * accuracy sobre el conjunto de prueba\n",
        "* mostrar por pantalla el número de época para verificar el avance del entrenamiento\n",
        "\n",
        "**Tip**: se recomienda usar la función `add_scalars()` del `SummaryWriter` para asegurarse que las dos pérdidas y los dos accuracy se muestren en gráficos diferentes.\n",
        "\n",
        "**Aclaraciones**:\n",
        "* La función de pérdida a utilizar debe ser **la entropía cruzada**\n",
        "* El algoritmo de optimización a utilizar debe ser **Adam** con todos sus parámetros por defecto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVxcPglySSRT"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "def train(net, train_iter, test_iter, writer,name, num_epochs):\n",
        "  \n",
        "  optimizador = torch.optim.Adam(net.parameters())\n",
        "  for epoch in range(num_epochs):\n",
        "    for X, y in train_iter:\n",
        "      optimizador.zero_grad()\n",
        "      l = loss(net(X), y)\n",
        "      l.backward()\n",
        "      optimizador.step()\n",
        "    train_accuracy, train_loss = evaluate_accuracy(net, train_iter, loss)\n",
        "    #print(train_accuracy, train_loss)\n",
        "    if test_iter is not None:\n",
        "\n",
        "      test_accuracy, test_loss = evaluate_accuracy(net, test_iter, loss)\n",
        "\n",
        "      writer.add_scalar(name+\"Loss/train\", train_loss, epoch)\n",
        "      writer.add_scalar(name+\"Accuracy/train\", train_accuracy, epoch)\n",
        "      writer.add_scalar(name+\"Loss/test\", test_loss, epoch)\n",
        "      writer.add_scalar(name+\"Accuracy/test\", test_accuracy, epoch)\n",
        "\n",
        "  return train_loss, test_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhtwKDqysBw0"
      },
      "source": [
        "### Actividad 5\n",
        "\n",
        "Utilizar la función train implementada en la actividad anterior para entrenar los 3 modelos generados en la Actividad 2. Luego utilizar TensorBoard para graficar su proceso de entrenamiento. En base a estas curvas responder si alguno de ellos está sufriendo overfitting o underfitting.\n",
        "\n",
        "**Aclaraciones**: \n",
        "* El batch_size debe ser de 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZWsQQtXV-eA"
      },
      "source": [
        "train(modelo_chico, data_iter_train, data_iter_test, writer, 'Modelo chico',500)\n",
        "\n",
        "writer.flush()\n",
        "#writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bd21Wr67YWX"
      },
      "source": [
        "train(modelo_medio, data_iter_train, data_iter_test, writer, 'Modelo mediano',500)\n",
        "writer.flush()\n",
        "#writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw7Ie54g7YdQ"
      },
      "source": [
        "train(modelo_grande, data_iter_train, data_iter_test, writer, 'Modelo grande', 500)\n",
        "writer.flush()\n",
        "#writer.close"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bQiME9Hlmpk"
      },
      "source": [
        "!rm -rf ./runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdVhEEHNf9xC"
      },
      "source": [
        "import os\n",
        "LOG_DIR = 'runs'\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj2tLqbfNbL6"
      },
      "source": [
        "!tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3AlvWfRG_Ty"
      },
      "source": [
        "##Respuestas:\n",
        "\n",
        "Podemos ver que el único caso que no presenta Overtifiting es el del Modelo Chico. Tanto el Modelo Grande como el mediano, aunque este último en menor medida,  Overfitean. En ambos, el modelo en el train se ajusta muy bien, pero no generaliza bien."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NemYlPxuwQv"
      },
      "source": [
        "### Actividad 6 (Opcional)\n",
        "Utilizar la función anterior para entrenar 10 modelos nuevos. Estos modelos deben tener 2 capas ocultas y una capa de salida como los de la Actividad 2. LA diferencia es que vamos a variar la cantidad de neuronas por capa entre las potencias desde $2^{0}$  hasta $2^{10}$. \n",
        "\n",
        "Para cada uno de esos modelos finales, almacenar en `train_loss` el valor de la función de pérdida sobre el conjunto de entrenamiento y en `test_loss`,el valor sobre el conjunto de prueba.\n",
        "\n",
        "Por último, utilizar la función provista para graficar los datos y comparar con el gráfico de Sesgo vs Varianza visto en clase. ¿Cuál sería el tamaño óptimo entre los relevados?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLOUyh6-RlA3"
      },
      "source": [
        "train_loss = []\n",
        "test_loss = []\n",
        "neurons = []\n",
        "\n",
        "for i in range(0,11):\n",
        "  print(i)\n",
        "  neurons.append(2**i)\n",
        "  modelo = nn.Sequential(nn.Linear(In_features,2**i),\n",
        "                        nn.Linear(2**i,2**i),nn.ReLU(),\n",
        "                        nn.Linear(2**i,2**i),nn.ReLU(),\n",
        "                        nn.Linear(2**i,out_features))\n",
        "  trainloss, testloss = train(modelo, data_iter_train, data_iter_test, writer, 'Modelo2**{}'.format(i),500)\n",
        "  train_loss.append(trainloss)\n",
        "  test_loss.append(testloss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsyknVEXUm_C",
        "outputId": "22e3b575-927b-4826-ef4f-65c76ab4582f"
      },
      "source": [
        "neurons"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RShtMgUCb9IS"
      },
      "source": [
        "df = pd.DataFrame(list(zip(neurons, train_loss,test_loss)),\n",
        "               columns =['Neuronas_por_capa', 'Error_Entrenamiento', 'Error_Prueba'])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abAs1eNusAQ1"
      },
      "source": [
        "def plot(df):\n",
        "  # multiple line plots\n",
        "  K = range(0,12,2)\n",
        "  neurons = [2**k for k in K]\n",
        "  plt.plot( 'Neuronas_por_capa', 'Error_Entrenamiento', data=df, marker='', color='skyblue', linewidth=2)\n",
        "  plt.plot( 'Neuronas_por_capa', 'Error_Prueba', data=df, marker='', color='olive', linewidth=2)\n",
        "  # show legend\n",
        "  plt.legend()\n",
        "  plt.xscale('log')\n",
        "  plt.xticks(neurons,[str(x)for x in neurons])\n",
        "  # show graph\n",
        "  plt.show()"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "LegqDvZQURgi",
        "outputId": "29f77c53-98b2-494c-d6fd-599943cf990d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot(df)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZjRJJs7SNQ3"
      },
      "source": [
        "Viendo el gráfico nos damos cuenta que el mejor modelo es aquel que tiene 4 neuronas. Con él, el error de generalización es el más bajo. Si seguimos aumentando la complejidad del modelo nos damos cuenta que el error en el set de Train disminuye, pero el error en el set de test aumenta. Esto quiere decir que se produce Overfiting con modelos más complejos (Podemos hablar de Overfiting cuando la línea que visualiza el error de test asciende por arriba de la línea que visualiza en error en el set de Train)."
      ]
    }
  ]
}