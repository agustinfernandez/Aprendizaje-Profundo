{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Agustín Fernández - Trabajo Práctico N°6: Clasificación usando Redes Neuronales Recurrentes",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBxMRJlbxnRG"
      },
      "source": [
        "#@title Aprendizaje Profundo | Otoño 2021 by Datitos{display-mode: \"form\" }\n",
        "#@markdown ![71335171.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAACwElEQVR4nOzdMY7iQBBA0WU197/FnJNNJ/FqWvLHZfd7McIGfVVQos3X+/3+A2f7e/UN8EzCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBJfV9/A/7xer6XX3/1/gZ70eU0sEsIiISwSwiIhLBLCIiEsEiP2WEf7m9U9zVnvU9vh85pYJIRFQlgkhEVCWCSERUJYJEbssc5ytL+5at8zec9UM7FICIuEsEgIi4SwSAiLhLBIPGqPdWR1v1VfdwcmFglhkRAWCWGREBYJYZEQFokt9lhHdt4z1UwsEsIiISwSwiIhLBLCIiEsEh/dY+18zq4w7RzlTyYWCWGREBYJYZEQFglhkRAWiS1+jzVhr/Mbd7nP3zCxSAiLhLBICIuEsEgIi4SwSDxqj1U/72r1ulc9l2sCE4uEsEgIi4SwSAiLhLBICIvE7D3W9/fSy6/63dLqdZfvc/F7mMDEIiEsEsIiISwSwiIhLBLCIjF7j3WSs87rTXufyUwsEsIiISwSwiIhLBLCIiEsEq8Ju5N6r3OXc3xP2oeZWCSERUJYJIRFQlgkhEVCWCRG7LGOTN7TfNIdvwcTi4SwSAiLhLBICIuEsEgIi8Toc4U7Pyf9p8n7qiMmFglhkRAWCWGREBYJYZEQFonRe6wjd9zr7MbEIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIi8S8AAP//HtRtH09JwIEAAAAASUVORK5CYII=)\n",
        "#El siguiente notebook fue traducido por Pablo Marinozi como el cuarto trabajo práctico correspondiente a la versión de Otoño del 2021 del curso Aprendizaje Profundo organizado por Datitos\n",
        "#El tutorial original fue diseñado por Ben Trevett y fue publicado en su github https://github.com/bentrevett\n",
        "#Para mayor información consultar https://datitos.github.io/curso-aprendizaje-profundo/#calendario"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqV37c_3yVoH"
      },
      "source": [
        "# Trabajo Práctico N°6: Clasificación usando Redes Neuronales Recurrentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gc419sbFyhp"
      },
      "source": [
        "# Sección 1 - Análisis de sentimiento simple\n",
        "\n",
        "En este práctico, crearemos un modelo de aprendizaje automático para detectar sentimientos (es decir, detectar si una oración es positiva o negativa) usando PyTorch y TorchText. Esto se hará en reseñas de películas, utilizando el [conjunto de datos de IMDb](http://ai.stanford.edu/~amaas/data/sentiment/).\n",
        "\n",
        "Comenzaremos de manera muy simple para comprender los conceptos generales sin preocuparnos realmente por los buenos resultados. Las siguientes secciones se basarán en estos conceptos y obtendremos buenos resultados.\n",
        "\n",
        "### Introducción\n",
        "\n",
        "Usaremos una **red neuronal recurrente** (RNN), ya que se usan comúnmente en el análisis de secuencias. Un RNN toma una secuencia de palabras, $X = \\{x_1, ..., x_T \\}$, una a la vez, y produce un _estado oculto_, $h$, para cada palabra. Usamos el RNN _recurrentemente_ introduciendo la palabra actual $x_t$ así como el estado oculto de la palabra anterior, $h_{t-1}$, para producir el siguiente estado oculto, $h_t$.\n",
        "\n",
        "$$h_t = \\text{RNN}(x_t, h_{t-1})$$\n",
        "\n",
        "Una vez que tenemos nuestro estado oculto final, $h_T$, (a partir de la última palabra en la secuencia, $x_T$) lo alimentamos a través de una capa lineal, $f$, (también conocida como capa densa), para recibir nuestro sentimiento predicho, $\\hat{y} = f(h_T)$.\n",
        "\n",
        "A continuación se muestra una oración de ejemplo, con la RNN prediciendo cero, lo que indica un sentimiento negativo. La RNN se muestra en naranja y la capa lineal se muestra en plateado. Tenga en cuenta que usamos la misma RNN para cada palabra, es decir, tiene los mismos parámetros. El estado oculto inicial, $ h_0 $, es un tensor inicializado a todos ceros.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment1.png?raw=1)\n",
        "\n",
        "**Nota:** algunas capas y pasos se han omitido del diagrama, pero se explicarán más adelante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wALYs4TxFyhs"
      },
      "source": [
        "## Preparando los datos\n",
        "\n",
        "Uno de los conceptos principales de TorchText es el \"Field\". Estos definen cómo se deben procesar tus datos. En nuestra tarea de clasificación de sentimientos, los datos consisten en la cadena sin procesar de la reseña y la etiqueta, ya sea \"pos\" o \"neg\".\n",
        "\n",
        "Los parámetros de un \"Field\" especifican cómo se deben procesar los datos.\n",
        "\n",
        "Usamos el campo `TEXT` para definir cómo se debe procesar la reseña y el campo` LABEL` para procesar la opinión.\n",
        "\n",
        "Nuestro Field `TEXT` tiene` tokenize = 'spacy'` como argumento. Esto define que la \"tokenización\" (el acto de dividir la cadena en \"tokens\" discretos) debe realizarse utilizando el tokenizador [spaCy](https://spacy.io). Si no se pasa ningún argumento `tokenize`, el valor predeterminado es simplemente dividir la cadena en espacios. También necesitamos especificar un `tokenizer_language` que le dice a torchtext qué modelo de spaCy usar. Usamos el modelo `en_core_web_sm` que debe descargarse con ` python -m spacy download en_core_web_sm` antes de ejecutar este notebook.\n",
        "\n",
        "\"LABEL\" se define mediante un \"LabelField\", un subconjunto especial de la clase \"Field\" que se utiliza específicamente para manipular etiquetas. Explicaremos el argumento `dtype` más adelante.\n",
        "\n",
        "Para obtener más información sobre `Fields`, vaya [aquí](https://github.com/pytorch/text/blob/master/torchtext/data/field.py).\n",
        "\n",
        "También establecemos las semillas aleatorias para la reproducibilidad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt_WATfwFyhu"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQTQEs1SFyhu"
      },
      "source": [
        "Otra característica útil de TorchText es que tiene soporte para conjuntos de datos comunes utilizados en el procesamiento del lenguaje natural (NLP).\n",
        "\n",
        "El siguiente código descarga automáticamente el conjunto de datos de IMDb y lo divide en las divisiones canónicas de entrenamiento/prueba como objetos `torchtext.datasets`. Procesa los datos utilizando los `Fields` que hemos definido previamente. El conjunto de datos de IMDb consta de 50.000 reseñas de películas, cada una etiquetada como reseña positiva o negativa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myUGQPJGFyhw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "0579be25-939e-4bc9-fbda-f58a41464ed6"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-368abd8fe573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMDB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/datasets/imdb.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, text_field, label_field, root, train, test, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         return super(IMDB, cls).splits(\n\u001b[1;32m     54\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_field\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_field\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_field\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             train=train, validation=None, test=test, **kwargs)\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/dataset.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         train_data = None if train is None else cls(\n\u001b[0;32m---> 78\u001b[0;31m             os.path.join(path, train), **kwargs)\n\u001b[0m\u001b[1;32m     79\u001b[0m         val_data = None if validation is None else cls(\n\u001b[1;32m     80\u001b[0m             os.path.join(path, validation), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/datasets/imdb.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, text_field, label_field, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMDB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/example.py\u001b[0m in \u001b[0;36mfromlist\u001b[0;34m(cls, data, fields)\u001b[0m\n\u001b[1;32m     82\u001b[0m                         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    207\u001b[0m         `preprocessing` Pipeline.\"\"\"\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/data/utils.py\u001b[0m in \u001b[0;36m_spacy_tokenize\u001b[0;34m(x, spacy)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_spacy_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc._get_chunker\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mget_lang_class\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Check if language is registered / entry point is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/catalogue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mfrom_entry_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfrom_entry_point\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_entry_point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/catalogue.py\u001b[0m in \u001b[0;36mget_entry_point\u001b[0;34m(self, name, default)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mentry\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mentry_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAVAILABLE_ENTRY_POINTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mentry_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mentry_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name, default)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mflake8_bypass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mflake8_bypass\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0mis_flake8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flake8'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_flake8\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m     \u001b[0;34m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetouterframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0mframelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m         \u001b[0mframeinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m             \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    766\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Invalidate cache if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;31m# or it is in the linecache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_filesbymodname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m                 \u001b[0;31m# Have already mapped this module, so skip it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdxAtYMN9Z1i"
      },
      "source": [
        "La celda anterior tarda mucho tiempo en ejecutarse debido a que el método de tokenización spaCy es bastante lento. Por eso vamos a guardar los datos tokenizados en archivos para cargarlos de disco cada vez que queramos usarlos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7-sBtud9Yne"
      },
      "source": [
        "import json\n",
        "\n",
        "train_examples = [vars(t) for t in train_data]\n",
        "test_examples = [vars(t) for t in test_data]\n",
        "\n",
        "with open('train.json', 'w+') as f:\n",
        "    for example in train_examples:\n",
        "        json.dump(example, f)\n",
        "        f.write('\\n')\n",
        "        \n",
        "with open('test.json', 'w+') as f:\n",
        "    for example in test_examples:\n",
        "        json.dump(example, f)\n",
        "        f.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soR9u-kD-y1t"
      },
      "source": [
        "Para cargar los datos desde disco, usamos el siguiente código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L04sKUdJ-oRg"
      },
      "source": [
        "TEXT = data.Field()\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "\n",
        "fields = {'text': ('text', TEXT), 'label': ('label', LABEL)}\n",
        "\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path = '/content',\n",
        "    train = 'train.json',\n",
        "    test = 'test.json',\n",
        "    format = 'json',\n",
        "    fields = fields\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nug7H88aFyhx"
      },
      "source": [
        "Podemos ver cuántos ejemplos hay en cada división comprobando su longitud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-r4AXRCFyhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122c5064-abaa-4d5a-a9c7-64e5d9c10568"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 13632\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z8SCQgJFyhy"
      },
      "source": [
        "También podemos comprobar un ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2AXjDRwFyh0"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5vloCrJFyh1"
      },
      "source": [
        "El conjunto de datos de IMDb solo tiene divisiones de entrenamiento/prueba, por lo que necesitamos crear un conjunto de validación. Podemos hacer esto con el método `.split()`.\n",
        "\n",
        "De forma predeterminada, esto divide 70/30, sin embargo, al pasar un argumento `split_ratio`, podemos cambiar la proporción de la división, es decir, un` split_ratio` de 0.8 significaría que el 80% de los ejemplos componen el conjunto de entrenamiento y el 20% componen el conjunto de validación.\n",
        "\n",
        "También pasamos nuestra semilla aleatoria al argumento `random_state`, asegurándonos de obtener la misma división de entrenamiento/validación cada vez que lo ejecutemos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu2Ro_T1Fyh1"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2hC6zLcFyh3"
      },
      "source": [
        "Nuevamente, vamos a ver cuántos ejemplos hay en cada división."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hfUPQxfFyh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb1f05bc-2af9-4139-983f-6f59e0bc8f8b"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOrNbWSIFyh4"
      },
      "source": [
        "A continuación, tenemos que construir un _vocabulario_. Ésta es efectivamente una tabla de búsqueda donde cada palabra única en su conjunto de datos tiene un _indice_ correspondiente (un número entero).\n",
        "\n",
        "Hacemos esto porque nuestro modelo de aprendizaje automático no puede operar con cadenas, solo con números. Cada _índice_ se utiliza para construir un vector _one-hot_ para cada palabra. Un vector one-hot es un vector donde todos los elementos son 0, excepto uno, que es 1, y la dimensionalidad es el número total de palabras únicas en su vocabulario, comúnmente denotado por $ V $.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment5.png?raw=1)\n",
        "\n",
        "La cantidad de palabras únicas en nuestro conjunto de entrenamiento es de más de 100.000, lo que significa que nuestros vectores one-hot tendrán más de 100.000 dimensiones. Esto hará que el entrenamiento sea lento y posiblemente no se ajuste a su GPU (si está usando una).\n",
        "\n",
        "Hay dos formas de reducir nuestro vocabulario de manera efectiva: solo podemos tomar las $n$ palabras más comunes o ignorar las palabras que aparecen menos de $m$ veces. Haremos lo primero, manteniendo solo las 25.000 palabras más usadas en el dataset.\n",
        "\n",
        "¿Qué hacemos con las palabras que aparecen en los ejemplos pero que hemos sacado del vocabulario? Los reemplazamos con un token especial _unknown_ o ``. Por ejemplo, si la oración fuera \"This film is great and I love it\", pero la palabra \"love\" no estaba en el vocabulario, se convertiría en \"This film is great and I <unk> it\".\n",
        "\n",
        "La siguiente celda construye el vocabulario, manteniendo solo los tokens `max_size` más comunes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnID60TQFyh4"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpp6rmmuFyh4"
      },
      "source": [
        "¿Por qué construimos el vocabulario usando solo el conjunto de entrenamiento? Al probar cualquier sistema de aprendizaje automático, no tenemos que mirar el conjunto de prueba de ninguna manera. Tampoco incluimos el conjunto de validación porque queremos que refleje el conjunto de prueba tanto como sea posible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq6VlUp8Fyh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca680e6d-70d9-4cf2-9726-9696f6f24f7a"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FgJCec9Fyh6"
      },
      "source": [
        "¿Por qué el tamaño de vocabulario es 25002 y no 25000? Uno de los tokens añadidos es el token `<unk>` y el otro es un token `<pad>`.\n",
        "\n",
        "Cuando ingresamos oraciones en nuestro modelo, ingresamos un _lote_ de ellas a la vez, es decir, más de una a la vez, y todas las oraciones del lote deben tener el mismo tamaño. Por lo tanto, para garantizar que cada oración del lote sea del mismo tamaño, se rellena cualquier frase más corta que la más larga del lote con tokens `<pad>`.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment6.png?raw=1)\n",
        "\n",
        "También podemos ver las palabras más comunes del vocabulario y sus frecuencias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNUjSQsQFyh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164ac190-823b-42ff-91fa-9ba9f8a9a570"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 200156), ('a', 108181), ('and', 106418), ('of', 99511), ('to', 92452), ('is', 72025), ('in', 59506), ('I', 46002), ('that', 45089), ('this', 39889), ('it', 38102), ('/><br', 35889), ('was', 32750), ('as', 29657), ('with', 28966), ('for', 28697), ('The', 23621), ('but', 23587), ('on', 21514), ('movie', 21232)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAlDaC-aFyh6"
      },
      "source": [
        "También podemos ver el vocabulario directamente usando el método `stoi`(**s**tring **to** **i**nt) o el método `itos` (**i**nt **to**  **s**tring)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlL0ib33Fyh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37970095-ade2-4e0c-a6db-a926aafeaddb"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'I']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3zYfhn8Fyh7"
      },
      "source": [
        "También podemos verificar las etiquetas, asegurándonos de que 0 sea negativo y 1 sea positivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGCVr0V0Fyh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d714e83-a963-4440-ecfd-f78e103e0557"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F58J3QuKFyh8"
      },
      "source": [
        "El paso final de la preparación de los datos es la creación de los iteradores. Repetimos estos en el ciclo de entrenamiento/evaluación, y devuelven un lote de ejemplos (indexados y convertidos en tensores) en cada iteración.\n",
        "\n",
        "Usaremos un `BucketIterator` que es un tipo especial de iterador que devolverá un lote de ejemplos donde cada ejemplo tiene una longitud similar, minimizando la cantidad de tokens de relleno.\n",
        "\n",
        "También queremos colocar los tensores devueltos por el iterador en la GPU (si está usando uno). PyTorch maneja esto usando `torch.device`, luego pasamos este dispositivo al iterador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjgYAmlfFyh8"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort=False,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhUiPqsxFyh8"
      },
      "source": [
        "## Construcción del modelo\n",
        "\n",
        "La siguiente etapa es construir el modelo que eventualmente vamos a entrenar y evaluar.\n",
        "\n",
        "Nuestra clase `RNN` es una subclase de` nn.Module`.\n",
        "\n",
        "Dentro del `__init__` definimos las _capas_ del módulo. Nuestras tres capas son una capa _embedding_, nuestra RNN y una capa _densa_. Todas las capas tienen sus parámetros inicializados a valores aleatorios, a menos que se especifique explícitamente.\n",
        "\n",
        "La capa de embedding se utiliza para transformar nuestro vector ralos one-hot (ralos ya que la mayoría de los elementos son 0) en un vector de embedding denso (denso ya que la dimensionalidad es mucho más pequeña y todos los elementos son números reales). Esta capa de embedding es simplemente una capa densa única. Además de reducir la dimensionalidad de la entrada al RNN, existe la teoría de que las palabras que tienen un impacto similar en el sentimiento de la revisión se mapean juntas en este denso espacio vectorial. Para obtener más información sobre los embeddings de palabras, consulte [aquí](https://monkeylearn.com/blog/word-embeddings-transform-text-numbers/).\n",
        "\n",
        "La capa RNN es nuestra RNN que toma nuestro vector denso y el estado oculto anterior $h_{t-1}$, y lo usa para calcular el siguiente estado oculto, $ h_t $.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment7.png?raw=1)\n",
        "\n",
        "Finalmente, la capa linear toma el estado oculto final y lo alimenta a través de una capa densa, $ f(h_T) $, transformándola a la dimensión de salida correcta.\n",
        "\n",
        "Se llama al método `forward` cuando introducimos ejemplos en nuestro modelo.\n",
        "\n",
        "Cada lote, `text`, es un tensor de tamaño **[longitud de la oración, tamaño del lote]**. Es un lote de oraciones, cada una de las cuales tiene cada palabra convertida en un vector one-hot.\n",
        "\n",
        "Puede notar que este tensor debería tener otra dimensión debido a los vectores one-hot, sin embargo PyTorch almacena convenientemente un vector one-hot como su valor de índice, es decir, el tensor que representa una oración es solo un tensor de los índices para cada token en ese oración. El acto de convertir una lista de tokens en una lista de índices se denomina comúnmente *numeralización*.\n",
        "\n",
        "El lote de entrada luego se pasa a través de la capa de embedding lo que nos da una representación vectorial densa de nuestras oraciones. `embedded` es un tensor de tamaño **[longitud de la oración, tamaño del lote, embedding_dim]**.\n",
        "\n",
        "`embedded` se introduce luego en el RNN. En algunos frameworks, debemos alimentar el estado oculto inicial, $ h_0 $, en el RNN. Sin embargo, en PyTorch, si no se pasa un estado oculto inicial como argumento, se establece de forma predeterminada en un tensor de todos ceros.\n",
        "\n",
        "El RNN devuelve 2 tensores, `output` de tamaño **[longitud de la oración, tamaño de lote, dimensión de la variable oculta]** y` hidden` de tamaño **[1, tamaño de lote, dimensión de la variable oculta]**. `output` es la concatenación del estado oculto de cada paso de tiempo, mientras que ` hidden` es simplemente el estado oculto final. Verificamos esto usando la declaración `assert`. Tenga en cuenta el método `squeeze`, que se utiliza para eliminar una dimensión de tamaño 1.\n",
        "\n",
        "Finalmente, alimentamos el último estado oculto, \"hidden\", a través de la capa lineal, \"fc\", para producir una predicción."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVmXcKVkFyh9"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        #########################################################################\n",
        "        #TO_DO: Configure las capas que necesita para la RNN con la arquitectura#\n",
        "        #       definida anteriormente.                                         #\n",
        "        #########################################################################\n",
        "        # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) ***** \n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "        # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "        ########################################################################\n",
        "        #                          FINAL DE TU CÓDIGO                          #       \n",
        "        ########################################################################\n",
        "        \n",
        "    def forward(self, text):\n",
        "        ########################################################################\n",
        "        # TODO: Implementá la función forward para la RNN. Deberías            #\n",
        "        # usar las capas que definiste en __init__ y especificar la            #\n",
        "        # conectividad de dichas capas                                         #\n",
        "        ########################################################################\n",
        "        # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        x = self.embed(text)\n",
        "        output , hidden = self.rnn(x)\n",
        "        hidden = torch.squeeze(hidden)\n",
        "        x = self.linear(hidden)\n",
        "        return x \n",
        "\n",
        "        # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "        ########################################################################\n",
        "        #                          FINAL DE TU CÓDIGO                          #       \n",
        "        ########################################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFCEMwZ3Fyh9"
      },
      "source": [
        "Ahora creamos una instancia de nuestra clase RNN.\n",
        "\n",
        "La dimensión de entrada es la dimensión de los vectores one-hot, que es igual al tamaño del vocabulario.\n",
        "\n",
        "La dimensión de embedding es el tamaño de los vectores de palabras densas. Suele tener entre 50 y 250 dimensiones, pero depende del tamaño del vocabulario.\n",
        "\n",
        "La dimensión oculta es el tamaño de las variables ocultas. Suele rondar entre 100 y 500 dimensiones, pero también depende de factores como el tamaño del vocabulario, el tamaño de los vectores densos y la complejidad de la tarea.\n",
        "\n",
        "La dimensión de salida suele ser el número de clases, sin embargo, en el caso de solo 2 clases, el valor de salida está entre 0 y 1 y, por lo tanto, puede ser unidimensional, es decir, un solo número real escalar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4LhijkrFyh9"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLAA1l7bFyh9"
      },
      "source": [
        "También creemos una función que nos diga cuántos parámetros entrenables tiene nuestro modelo para que podamos comparar el número de parámetros en diferentes modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ADp7jxFyh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec264f9-cd8d-469f-fdf9-c0023bdb12f4"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'El modelo tiene {count_parameters(model):,} parámetros entrenables')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo tiene 2,592,105 parámetros entrenables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul_5J7R_Fyh-"
      },
      "source": [
        "## Entrenar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh-CXICmFyh-"
      },
      "source": [
        "Ahora vamos a configurar el entrenamiento y a entrenar el modelo.\n",
        "\n",
        "Primero, crearemos un optimizador. Este es el algoritmo que usamos para actualizar los parámetros del módulo. Aquí, usaremos _descenso de gradiente estocástico_ (SGD). El primer argumento son los parámetros que serán actualizados por el optimizador y el segundo es la tasa de aprendizaje, es decir, cuánto cambiaremos los parámetros cuando hagamos una actualización de parámetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiT_6M0hFyh-"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPmiIiP7Fyh_"
      },
      "source": [
        "A continuación, definiremos nuestra función de pérdida. \n",
        "\n",
        "La función de pérdida aquí es _entropía cruzada binaria con logits_.\n",
        "\n",
        "Nuestro modelo genera actualmente un número real sin consolidar. Como nuestras etiquetas son 0 o 1, queremos restringir las predicciones a un número entre 0 y 1. Hacemos esto usando las funciones _sigmoidea_.\n",
        "\n",
        "Luego usamos este escalar para calcular la pérdida usando entropía cruzada binaria.\n",
        "\n",
        "La clase `BCEWithLogitsLoss` lleva a cabo los pasos de entropía cruzada sigmoidea y binaria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "429y_6BkFyh_"
      },
      "source": [
        "loss = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Nz1Os8Fyh_"
      },
      "source": [
        "Usando `.to`, podemos ubicar al modelo y la función de pérdida en el GPU (si tenemos alguno). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1corCOUXFyh_"
      },
      "source": [
        "model = model.to(device)\n",
        "loss = loss.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsgcrZkTFyiA"
      },
      "source": [
        "Ya establecimos cómo la pérdida, sin embargo, tenemos que escribir nuestra función para calcular el accuracy.\n",
        "\n",
        "Esta función primero alimenta las predicciones a través de una capa sigmoidea, reescalando los valores entre 0 y 1, luego los redondeamos al número entero más cercano. Esto redondea cualquier valor superior a 0,5 a 1 (un sentimiento positivo) y el resto a 0 (un sentimiento negativo).\n",
        "\n",
        "Luego calculamos cuántas predicciones redondeadas son iguales a las etiquetas reales y la promediamos en todo el lote."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDEz_jKKF8sr",
        "outputId": "6cd9e538-bf2b-46c9-f30f-a246849c4629"
      },
      "source": [
        "a = torch.ones(4) - 0.49\n",
        "a = torch.sigmoid(a)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6248, 0.6248, 0.6248, 0.6248])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nScl7_CGFyiA"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Devuelve el accuracy por lote, es decir, si obtiene 8/10 correctamente,\n",
        "    esto devuelve 0.8, NO 8\n",
        "    \"\"\"\n",
        "    ########################################################################\n",
        "    # TODO: Implementá la función binary_accuracy()                        #\n",
        "    ########################################################################\n",
        "    # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "\n",
        "    sigmod = torch.sigmoid(preds)\n",
        "    res = torch.round(sigmod)\n",
        "    return  torch.sum(res == y) / len(preds)\n",
        "      \n",
        "    #suma=0\n",
        "    # for x in range(0,len(res)-1):\n",
        "    #   if res[x] == y[x]:\n",
        "    #     suma = suma + 1\n",
        "    #   else:\n",
        "    #     suma = suma\n",
        "    \n",
        "    # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "    ########################################################################\n",
        "    #                          FINAL DE TU CÓDIGO                          #       \n",
        "    ########################################################################"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKU52miSFyiA"
      },
      "source": [
        "La función `train_epoch` itera sobre todos los ejemplos, un lote a la vez.\n",
        "\n",
        "`model.train()` se usa para poner el modelo en \"modo de entrenamiento\", lo que activa _ dropout_ y _batch normalization_. Aunque no los estamos usando en este modelo, es una buena práctica incluirlo.\n",
        "\n",
        "Para cada lote, primero ponemos a cero los gradientes. Cada parámetro en un modelo tiene un atributo \"grad\" que almacena el gradiente calculado. PyTorch no elimina automáticamente los gradientes calculados a partir del último cálculo de gradiente, por lo que deben ponerse a cero manualmente.\n",
        "\n",
        "Luego alimentamos el lote de oraciones, `batch.text`, en el modelo. Es necesario usar la función `squeeze` ya que las predicciones tienen inicialmente la forma **[tamaño de lote, 1]**, y necesitamos eliminar la dimensión de tamaño 1 ya que PyTorch espera que la entrada de predicciones a nuestra función de pérdida tenga forma **[tamaño del lote]**.\n",
        "\n",
        "Luego, la pérdida y el accuracy se calculan utilizando nuestras predicciones y las etiquetas.\n",
        "\n",
        "Calculamos el gradiente de cada parámetro con `loss.backward()`, y luego actualizamos los parámetros usando los gradientes y el algoritmo de optimización con `optimizer.step()`.\n",
        "\n",
        "La pérdida y el accuracy se acumulan a lo largo de la época. Finalmente, devolvemos la pérdida y el accuracy, promediadas a lo largo de la época.\n",
        "\n",
        "Recordemos que al inicializar el Field `LABEL`, configuramos` dtype = torch.float`. Esto se debe a que TorchText establece que los tensores sean `LongTensor`s por defecto, sin embargo, nuestra función de pérdida espera que ambas entradas sean` FloatTensor`s. Establecer el `dtype` en` torch.float`, hizo esto por nosotros. El método alternativo para hacer esto sería realizar la conversión dentro de la función `train` pasando` batch.label.float() `en lugar de` batch.label` a la función de pérdida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f269HhVqFyiB"
      },
      "source": [
        "def train_epoch(model, iterator, optimizer, loss):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    ########################################################################\n",
        "    # TODO: Implementá la función train_epoch() siguiendo las              #\n",
        "    #       instrucciones de arriba.                                       #\n",
        "    ########################################################################\n",
        "    # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "\n",
        "    for x,y in iterator:\n",
        "      optimizer.zero_grad()\n",
        "      salida_modelo = model(x)\n",
        "      perdida = loss(torch.squeeze(salida_modelo), y)\n",
        "      accuracy = binary_accuracy(torch.squeeze(salida_modelo), y)\n",
        "      perdida.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "      epoch_acc = epoch_acc + accuracy\n",
        "      epoch_loss = epoch_loss + perdida \n",
        "\n",
        "\n",
        "    # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "    ########################################################################\n",
        "    #                          FINAL DE TU CÓDIGO                          #       \n",
        "    ########################################################################\n",
        "    \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsv_u71tFyiB"
      },
      "source": [
        "`evaluate_epoch` es parecida a `train_epoch`, con algunas modificaciones ya que no desea actualizar los parámetros al evaluar.\n",
        "\n",
        "`model.eval()` pone el modelo en \"modo de evaluación\", esto apaga _ dropout_ y _batch normalization_. Nuevamente, no los usamos en este modelo, pero es una buena práctica incluirlos.\n",
        "\n",
        "No se calculan gradientes en las operaciones de PyTorch dentro del bloque `with no_grad()`. Esto hace que se utilice menos memoria y acelera el cálculo.\n",
        "\n",
        "El resto de la función es igual que `train`, con la eliminación de` optimizer.zero_grad() `,` loss.backward () `y` optimizer.step () `, ya que no actualizamos los parámetros del modelo cuando evaluamos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXHxKDsAFyiB"
      },
      "source": [
        "def evaluate_epoch(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    ########################################################################\n",
        "    # TODO: Implementá la función evaluate_epoch() siguiendo las           #\n",
        "    #       instrucciones de arriba.                                       #\n",
        "    ########################################################################\n",
        "    # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, y in iterator:\n",
        "        salida_modelo = model(x)\n",
        "        perdida = loss(torch.squeeze(salida_modelo), y)\n",
        "        accuracy = binary_accuracy(torch.squeeze(salida_modelo), y)\n",
        "        epoch_acc = epoch_acc + accuracy\n",
        "        epoch_loss = epoch_loss + perdida\n",
        "\n",
        "\n",
        "    # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "    ########################################################################\n",
        "    #                          FINAL DE TU CÓDIGO                          #       \n",
        "    ########################################################################\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GA6H7qbFyiB"
      },
      "source": [
        "También vamos a crear una función para decirnos cuánto tarda una época en entrenarse para comparar los tiempos de entrenamiento entre modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddWoeFYpFyiC"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWjnFd7MFyiC"
      },
      "source": [
        "Luego entrenamos el modelo a través de múltiples épocas, una época es un pase completo a través de todos los ejemplos en los conjuntos de entrenamiento y validación.\n",
        "\n",
        "En cada época, si la pérdida de validación es la mejor que hemos visto hasta ahora, guardaremos los parámetros del modelo y luego, una vez finalizado el entrenamiento, usaremos ese modelo en el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JBDTNHlFyiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42d4d5d-856a-46f6-df7e-c2a2853a7738"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train_epoch(model, train_iterator, optimizer, loss)\n",
        "    valid_loss, valid_acc = evaluate_epoch(model, valid_iterator, loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.18%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 49.70%\n",
            "Epoch: 02 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.08%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 48.31%\n",
            "Epoch: 03 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.50%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 49.71%\n",
            "Epoch: 04 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.41%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 48.31%\n",
            "Epoch: 05 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 48.96%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 48.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnZWN0kdFyiD"
      },
      "source": [
        "Es posible que haya notado que la pérdida no está disminuyendo realmente y la precisión es deficiente. Esto se debe a varios problemas con el modelo que mejoraremos en la siguiente sección.\n",
        "\n",
        "Finalmente, la métrica que realmente nos importa, la pérdida de prueba y el accuracy, que obtenemos de nuestros parámetros que nos dieron la mejor pérdida de validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjQrmx5ZFyiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84bf2ca-d38c-47e3-a162-39a20f77a8c3"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "\n",
        "test_loss, test_acc = evaluate_epoch(model, test_iterator, loss)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.693 | Test Acc: 49.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T3dLGzLLSTU"
      },
      "source": [
        "# Sección 2 - Análisis de Sentimiento Potenciado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSzBc_zfFvaQ"
      },
      "source": [
        "## Preparando los datos\n",
        "\n",
        "Como antes, estableceremos la semilla, definiremos los `Fields` y obtendremos las divisiones entrenamiento/validación/prueba.\n",
        "\n",
        "Usaremos **secuencias empaquetadas con padding**, lo que hará que nuestro RNN solo procese los tokens distintos a `<pad>` de nuestra secuencia, y para cualquier elemento `<pad>`, la \"salida\" será un tensor cero. Para usar secuencias empaquetadas con padding, tenemos que decirle al RNN la longitud de las secuencias reales. Hacemos esto configurando `include_lengths = True` para nuestro Field ` TEXT`. Esto hará que `batch.text` ahora sea una tupla, siendo el primer elemento nuestra oración (un tensor numérico que se ha rellenado) y el segundo elemento las longitudes reales de nuestras oraciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-lXG0PVFvaU"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm',\n",
        "                  include_lengths = True)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoS_clU-Fvae"
      },
      "source": [
        "Luego volvemos a cargar el dataset de IMDb."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsIvnLjmFvah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ab8126-cea0-43aa-8276-e0585e3e6ccc"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 78.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVeXLPrMFvaj"
      },
      "source": [
        "Y volvemos a crear nuestro conjunto de validación a partir del de entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSGBw9nOFvam"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgfzrKv5Fvbk"
      },
      "source": [
        "Lo siguiente es el uso de embeddings de palabras previamente entrenados. Ahora, en lugar de tener nuestras embeddings de palabras inicializados al azar, se inicializan con estos vectores pre-entrenados.\n",
        "Obtenemos estos vectores simplemente especificando qué vectores queremos y pasándolos como argumento a `build_vocab`. `TorchText` se encarga de descargar los vectores y asociarlos con las palabras correctas en nuestro vocabulario.\n",
        "\n",
        "Aquí, usaremos los vectores \"glove.6B.100d\". \"Glove\" es el algoritmo usado para calcular los vectores, ve [aquí](https://nlp.stanford.edu/projects/glove /) para más. \"6B\" indica que estos vectores se entrenaron en 6 mil millones de tokens y \"100d\" indica que estos vectores son 100-dimensionales.\n",
        "\n",
        "Puede ver los otros vectores disponibles [aquí](https://github.com/pytorch/text/blob/master/torchtext/vocab.py#L113).\n",
        "\n",
        "La teoría es que estos vectores pre-entrenados ya tienen palabras con un significado semántico similar juntas en el espacio vectorial, p. Ej. \"terrible\", \"horrible\", \"espantoso\" están cerca. Esto le da a nuestra capa de embedding una buena inicialización, ya que no tiene que aprender estas relaciones desde cero.\n",
        "\n",
        "**Nota**: estos vectores pesan aproximadamente 862 MB, así que tenga cuidado si tiene una conexión a Internet limitada.\n",
        "\n",
        "Por defecto, TorchText inicializará con cero aquellas palabras que estén en su vocabulario, pero no en los embeddings pre-entrenados. Esto no es deseable, por lo que en su lugar los inicializamos aleatoriamente configurando `unk_init` en` torch.Tensor.normal_`. Esto ahora inicializará esas palabras a través de una distribución gaussiana."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX9RR5fPFvbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3ba5ab-083b-410d-ad17-d5d5ed18fcc1"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.39MB/s]                          \n",
            "100%|█████████▉| 398178/400000 [00:14<00:00, 26812.79it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fAHLxkqFvbo"
      },
      "source": [
        "Como antes, creamos los iteradores, colocando los tensores en la GPU si hay uno disponible.\n",
        "\n",
        "Otra cosa para las secuencias empaquetadas con padding, todos los tensores dentro de un lote deben ordenarse según su longitud. Esto se maneja en el iterador configurando `sort_within_batch = True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vu-7lr_Fvbp"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9u69MfxFvbv"
      },
      "source": [
        "## Construcción del Modelo\n",
        "El modelo presenta los cambios más drásticos.\n",
        "\n",
        "###  Una arquitectura RNN diferente\n",
        "\n",
        "Usaremos una arquitectura RNN diferente llamada Long Short-Term Memory (LSTM). ¿Por qué una LSTM es mejor que una RNN estándar? Los RNN estándar sufren el [problema del gradiente que se desvanece](https://en.wikipedia.org/wiki/Vanishing_gradient_problem). Los LSTM superan esto al tener un estado recurrente adicional llamado **_célda_**, $c$, que puede considerarse como la \"memoria\" del LSTM, y el uso de múltiples **_compuertas_** que controlan el flujo de información dentro y fuera de la memoria. Para obtener más información, vaya [aquí](https://colah.github.io/posts/2015-08-Understanding-LSTMs/). \n",
        "\n",
        "Simplemente podemos pensar en el LSTM como una función de $ x_t $, $ h_t $ y $ c_t $, en lugar de solo $ x_t $ y $ h_t $.\n",
        "\n",
        "$$ (h_t, c_t) = \\text {LSTM} (x_t, h_t, c_t) $$\n",
        "\n",
        "Por lo tanto, el modelo que usa un LSTM se parece a (con las capas de incrustación omitidas):\n",
        "\n",
        "![](https://i.imgur.com/a8Qaw07.png)\n",
        "\n",
        "El estado inicial de la celda, $ c_0 $, al igual que la variable oculta inicial, se inicializa a un tensor de todos ceros. Sin embargo, la predicción del sentimiento todavía se realiza utilizando la variable oculta final, no el estado final de la celda, es decir, $ \\hat {y} = f (h_T) $.\n",
        "\n",
        "###  RNN Bidireccional\n",
        "\n",
        "El concepto detrás de una RNN bidireccional es simple. Además de tener una RNN procesando las palabras en la oración desde la primera hasta la última (una RNN hacia adelante), tenemos una segunda RNN procesando las palabras en la oración desde **la última a la primera** (una RNN hacia atrás) . En el tiempo $ t $, la RNN hacia adelante está procesando la palabra $ x_t $, y la RNN hacia atrás está procesando la palabra $ x_{T-t + 1} $.\n",
        "\n",
        "En PyTorch, los tensores de las variables ocultas (y los estados de celda) devueltos por las RNN hacia adelante y hacia atrás se apilan uno encima del otro en un solo tensor.\n",
        "\n",
        "Hacemos nuestra predicción de sentimiento usando una concatenación del último estado oculto de la RNN hacia adelante (obtenido de la palabra final de la oración), $ h_T ^ \\rightarrow $, y el último estado oculto de la RNN hacia atrás (obtenido a partir de la primera palabra de la oración), $ h_T ^ \\leftarrow $, es decir, $ \\hat {y} = f (h_T ^ \\rightarrow, h_T ^ \\leftarrow) $\n",
        "\n",
        "La siguiente imagen muestra una RNN bidireccional, con la RNN hacia adelante en naranja, la RNN hacia atrás en verde y la capa lineal en plateado.\n",
        "\n",
        "![](https://i.imgur.com/g1mAJXt.png)\n",
        "\n",
        "### RNN Multicapa\n",
        "\n",
        "Las RNN multicapa (también llamados *RNN profundas*) son otro concepto simple. La idea es que agreguemos RNN adicionales sobre la RNN estándar inicial, donde cada RNN agregado es otra *capa*. La salida de la variable oculta de la primera RNN (inferior) en el tiempo $ t $ será la entrada de la RNN por encima de ella en el paso de tiempo $ t $. Luego, la predicción se realiza a partir de la variable oculta final de la capa final (más alta).\n",
        "\n",
        "La siguiente imagen muestra una RNN unidireccional multicapa, donde el número de capa se da como superíndice. También tenga en cuenta que cada capa necesita su propia variable oculta inicial, $ h_0 ^ L $.\n",
        "\n",
        "![](https://i.imgur.com/wBKSBhx.png)\n",
        "\n",
        "### Regularización\n",
        "\n",
        "Aunque hemos agregado mejoras a nuestro modelo, cada una de ellas agrega parámetros adicionales. Cuantos más parámetros tenga en su modelo, mayor será la probabilidad de que su modelo se sobreajuste (memorice los datos de entrenamiento, lo que provoca un error de entrenamiento bajo pero un error de validación/prueba alto, es decir, una generalización deficiente para ejemplos nuevos e inéditos). \n",
        "\n",
        "Para combatir esto, usamos la regularización. Más específicamente, usamos un método de regularización llamado **dropout**. El dropout funciona al *eliminar* (configurando en 0) neuronas en una capa al azar durante un pase hacia adelante. La probabilidad de que se descarte cada neurona se establece mediante un hiperparámetro y cada neurona con dropout aplicado se considera de forma independiente. Una teoría sobre por qué funciona el dropout es que un modelo con parámetros abandonados puede verse como un modelo \"más simple\" (menos parámetros). Las predicciones de todos estos modelos \"más simples\" (una para cada pase hacia adelante) se promedian juntas dentro de los parámetros del modelo. Por lo tanto, su único modelo puede considerarse como un conjunto de modelos más simples, ninguno de los cuales está sobre parametrizado y, por lo tanto, no debe sobreajustarse.\n",
        "\n",
        "### Detalles de Implementación\n",
        "\n",
        "Otra adición a este modelo es que no vamos a aprender el embedding del token `<pad>`. Esto se debe a que queremos decirle explícitamente a nuestro modelo que los tokens de relleno son irrelevantes para determinar el sentimiento de una oración. Esto significa que el embedding del token de padding permanecerá como se inicializó (todos ceros). Hacemos esto pasando el índice de nuestro token `<pad>` como el argumento `padding_idx` a la capa` nn.Embedding`.\n",
        "\n",
        "Para usar un LSTM en lugar del RNN estándar, usamos `nn.LSTM` en lugar de` nn.RNN`. Además, tenga en cuenta que el LSTM devuelve la \"salida\" y una tupla con el estado final de la variable oculta y de la \"celda\", mientras que el RNN estándar solo devuelve la \"salida\" y el estado final de la variable oculta.\n",
        "\n",
        "Como el estado oculto final de nuestro LSTM tiene un componente hacia adelante y hacia atrás, que se concatenarán juntos, el tamaño de la entrada a la capa `nn.Linear` es el doble que el tamaño de la dimensión oculta.\n",
        "\n",
        "La implementación de la bidireccionalidad y la adición de capas adicionales se realizan pasando valores para los argumentos `num_layers` y` bidirectional` para el LSTM.\n",
        "\n",
        "El dropout se implementa inicializando una capa `nn.Dropout` (el argumento es la probabilidad de descartar cada neurona) y usándola dentro del método` forward` después de cada capa a la que queremos aplicar el dropout. **Nota**: nunca use dropout en las capas de entrada o salida (`text` o` fc` en este caso), solo desea usarlo en las capas intermedias. Las LSTM tienes un argumento de \"dropout\" que añade dropout en las conexiones entre las variables ocultas en una capa y las variables ocultas en la siguiente capa.\n",
        "\n",
        "Como estamos pasando las longitudes de nuestras oraciones para poder usar secuencias empaquetadas con padding, tenemos que agregar un segundo argumento, `text_lengths`, a` forward`.\n",
        "\n",
        "Antes de pasar nuestras embeddings al RNN, necesitamos empaquetarlas, lo que hacemos con `nn.utils.rnn.packed_padded_sequence`. Esto hará que nuestro RNN solo procese los elementos no rellenados de nuestra secuencia. Entonces, el RNN devolverá `package_output` (una secuencia empaquetada) así como los estados` hidden` y `cell` (ambos son tensores). Sin secuencias empaquetadas con padding, ` hidden` y `cell` son tensores del último elemento de la secuencia, que probablemente será un token de relleno; sin embargo, cuando se utilizan secuencias empaquetadas con padding, ambos son del último elemento no rellenado de la secuencia. Tenga en cuenta que el argumento `lengths` de` package_padded_sequence` debe ser un tensor de CPU, por lo que lo convertimos explícitamente en uno usando `.to('cpu')`.\n",
        "\n",
        "Luego descomprimimos la secuencia de salida, con `nn.utils.rnn.pad_packed_sequence`, para transformarla de una secuencia empaquetada a un tensor. Los elementos de \"salida\" de los tokens de relleno serán tensores cero (tensores donde cada elemento es cero). \n",
        "\n",
        "El estado final de la variable oculta, `hidden`, tiene una forma de **[núm capas * núm direcciones, tamaño de lote, dimensión de la variable oculta]**. Estos están ordenados: **[forward_layer_0, backward_layer_0, forward_layer_1, backward_layer 1, ..., forward_layer_n, backward_layer n]**. Como queremos que la capa final (superior) avance y retroceda las variables ocultas, obtenemos las dos capas superiores ocultas de la primera dimensión, `hidden [-2,:,:]` y `hidden [-1,:,:]` y las concatenamos antes de pasarlas a la capa lineal (después de aplicar dropout)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "law_LyuRFvby"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 dropout, pad_idx, bidirectional, bias, batch_first ):\n",
        "        #########################################################################\n",
        "        #TO_DO: Configure las capas que necesita para la LSTM bidireccional     #\n",
        "        #       multicapa con regularización definida anteriormente.            #\n",
        "        #########################################################################\n",
        "        # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) ***** \n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bias, batch_first, dropout, bidirectional )\n",
        "        self.linear = nn.Linear(hidden_dim*2, output_dim)\n",
        "        self.dropout_ = nn.Dropout(dropout)\n",
        "        \n",
        "\n",
        "        # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "        ########################################################################\n",
        "        #                          FINAL DE TU CÓDIGO                          #       \n",
        "        ########################################################################\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        ########################################################################\n",
        "        # TODO: Implementá la función forward para la LSTM. Deberías           #\n",
        "        # usar las capas que definiste en __init__ y especificar la            #\n",
        "        # conectividad de dichas capas siguiendo los detalles de implementación#\n",
        "        # definidos arriba                                                     #\n",
        "        ########################################################################\n",
        "        # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        #empaquetamiento de la secuencia\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #la salida de los tokens de padding son tensores con ceros\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concatenación de las variables ocultas hacia adelante y hacia atrás\n",
        "        #y aplicar dropout\n",
        "\n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        \n",
        "        \n",
        "        x = self.embedding(text)\n",
        "        x = torch.nn.utils.rnn.pack_padded_sequence(x, text_lengths.to('cpu') )\n",
        "        package_output, tupla = self.lstm(x)\n",
        "        x , x_len =torch.nn.utils.rnn.pad_packed_sequence(package_output)\n",
        "        hidden = tupla[0]\n",
        "        hidden_final = torch.cat((hidden [-2,:,:], hidden [-1,:,:]), 1)\n",
        "        hidden_final = self.dropout_(hidden_final)\n",
        "        #hidden_final = hidden_final.reshape(-1, 64*256*2)\n",
        "        x_final = self.linear(hidden_final)\n",
        "        x_final = x_final.squeeze(1)\n",
        "        \n",
        "        return x_final\n",
        "        \n",
        "\n",
        "        # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "        ########################################################################\n",
        "        #                          FINAL DE TU CÓDIGO                          #       \n",
        "        ########################################################################\n",
        "        \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ19C3QGFvbz"
      },
      "source": [
        "Como antes, crearemos una instancia de nuestra clase RNN, con los nuevos parámetros y argumentos para el número de capas, bidireccionalidad y probabilidad de dropout.\n",
        "\n",
        "Para garantizar que los vectores entrenados previamente se puedan cargar en el modelo, el `EMBEDDING_DIM` debe ser igual al de los vectores GloVe previamente entrenados cargados anteriormente.\n",
        "\n",
        "Obtenemos nuestro índice de token de pad del vocabulario, obteniendo la cadena real que representa el token de pad del atributo `pad_token` del campo, que es` <pad> `por defecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkMFWcHLFvb0"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "BIAS = True\n",
        "BATCH_SIZE= False\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS,  \n",
        "            DROPOUT, \n",
        "            PAD_IDX, \n",
        "            BIDIRECTIONAL,\n",
        "            BIAS, \n",
        "            BATCH_SIZE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRNx1zl2Fvb2"
      },
      "source": [
        "Vamos a imprimir el número de parámetros en nuestro modelo.\n",
        "\n",
        "¡Fijate cómo tenemos casi el doble de parámetros que antes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L_JDeL_Fvb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcfa010-50f4-497e-d6ef-1b83928169f3"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'El modelo tiene {count_parameters(model):,} parámetros entrenables')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo tiene 4,810,857 parámetros entrenables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTMRZ8q3Fvb3"
      },
      "source": [
        "La última adición es copiar los embeddinga de palabras previamente entrenados en la capa \"embeddings\" de nuestro modelo.\n",
        "\n",
        "Recuperamos los embeddings del vocabulario del Field y verificamos que sean del tamaño correcto,  **_[tamaño de vocabulario, dimensión de los embeddings]_**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XU8Nlg0Fvb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714ea95a-316b-4994-973d-4ef82d2e0ced"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru_DnRLNFvb4"
      },
      "source": [
        "Luego, reemplazamos los pesos iniciales de la capa de \"embedding\" con los embeddings pre-entrenados.\n",
        "\n",
        "**Nota**: ¡esto siempre debe hacerse en el `weight.data` y no en el` weight`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGhneuUsFvb4"
      },
      "source": [
        "#inserte el código aquí para inicializar con los embeddings preentrenados\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.embedding.weight.requires_grad = False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz8Te59BFvb5"
      },
      "source": [
        "Como nuestros tokens `<unk>` y `<pad>` no están en el vocabulario pre-entrenado, han sido inicializados usando al construir nuestro vocabulario `unk_init` (una distribución $ \\mathcal {N} (0,1) $). Es preferible inicializar ambos a todos ceros para decirle explícitamente a nuestro modelo que, inicialmente, son irrelevantes para determinar el sentimiento.\n",
        "\n",
        "Hacemos esto estableciendo manualmente su fila en la matriz de pesos de incrustación en ceros. Obtenemos su fila encontrando el índice de los tokens, lo que ya hemos hecho para el índice de relleno.\n",
        "\n",
        "**Nota**: al igual que al inicializar los embeddings, ¡esto debe hacerse en el `weight.data` y no en el` weight`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aaokIrRFvb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3041f86b-a93c-413e-ef61-1b46dcbaf209"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "#inserte su código aquí para inicializar con ceros los tokens <unk> y <pad> \n",
        "model.embedding.weight.data[UNK_IDX, :] = 0\n",
        "model.embedding.weight.data[PAD_IDX, :] = 0\n",
        "\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.3335,  0.0274,  0.1259,  ..., -0.0510,  0.3407,  0.6567],\n",
            "        [-0.0734,  0.0609, -0.5752,  ...,  0.3456,  0.3631, -0.2070],\n",
            "        [-0.1278,  0.0041,  1.0966,  ...,  0.1481,  0.7298, -0.3969]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_1_CfqFFvcA"
      },
      "source": [
        "Ahora podemos ver que las dos primeras filas de la matriz de pesos de incrustación se han establecido en ceros. A medida que pasamos el índice del token de pad al `padding_idx` de la capa de embedding, este permanecerá en ceros durante el entrenamiento, sin embargo, sí se aprenderá el embedding del token `<unk>`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q85Qy9lFvcA"
      },
      "source": [
        "## Entrenamiento del Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou01-xMSFvcB"
      },
      "source": [
        "Ahora a entrenar el modelo.\n",
        "\n",
        "El único cambio que vamos a hacer acá es cambiar el optimizador de \"SGD\" a \"Adam\". SGD actualiza todos los parámetros con la misma tasa de aprendizaje y elegir esta tasa de aprendizaje puede ser complicado. `Adam` adapta la tasa de aprendizaje para cada parámetro, dandole a los parámetros que se actualizan con mayor frecuencia tasas de aprendizaje más bajas y a los parámetros que se actualizan con poca frecuencia, tasas de aprendizaje más altas. Puede encontrar más información sobre `Adam` (y otros optimizadores) [aquí](http://ruder.io/optimizing-gradient-descent/index.html).\n",
        "\n",
        "Para cambiar `SGD` a` Adam`, simplemente cambiamos `optim.SGD` a` optim.Adam`, también tenga en cuenta que no tenemos que proporcionar una tasa de aprendizaje inicial para Adam, ya que PyTorch especifica una tasa de aprendizaje inicial predeterminada sensible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1liL9tFvcC"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC4al2EFFvcC"
      },
      "source": [
        "El resto de los pasos para entrenar el modelo no se modifican.\n",
        "\n",
        "Definimos la función de pérdida y la colocamos junto con el modelo en la GPU (si está disponible)..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSO1R2IxFvcD"
      },
      "source": [
        "loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "loss = loss.to(device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YJ4CLiXFvcO"
      },
      "source": [
        "Definimos una función para entrenar nuestro modelo.\n",
        "\n",
        "Como hemos establecido `include_lengths = True`, nuestro ` batch.text` ahora es una tupla, siendo el primer elemento el tensor numérico y el segundo elemento las longitudes reales de cada secuencia. Los separamos en sus propias variables, `text` y` text_lengths`, antes de pasarlos al modelo.\n",
        "\n",
        "**Nota**: como ahora estamos usando dropout, debemos recordar usar `model.train()` para asegurarnos de que el dropout esté \"activado\" durante el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqRm1B9wFvcP"
      },
      "source": [
        "def train_epoch(model, iterator):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    ########################################################################\n",
        "    # TODO: Implementá la función train_epoch() siguiendo las              #\n",
        "    #       instrucciones de arriba teniendo en cuenta las secuencias      #\n",
        "    #       empaquetadas con padding.                                      #\n",
        "    ########################################################################\n",
        "    # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "\n",
        "    for x,y in iterator:\n",
        "      optimizer.zero_grad()\n",
        "      text, text_length = x\n",
        "      salida_modelo = model(text, text_length)\n",
        "      #print(salida_modelo)\n",
        "      #print(y)\n",
        "      perdida = loss(salida_modelo, y)\n",
        "      accuracy = binary_accuracy(salida_modelo, y)\n",
        "      perdida.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "      epoch_acc = epoch_acc + accuracy \n",
        "      epoch_loss = epoch_loss + perdida \n",
        "\n",
        "    # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "    ########################################################################\n",
        "    #                          FINAL DE TU CÓDIGO                          #       \n",
        "    ########################################################################\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxe2rxEyFvcR"
      },
      "source": [
        "Luego definimos una función para probar nuestro modelo, recordando de nuevo separar `batch.text`.\n",
        "\n",
        "**Nota**: como ahora estamos usando dropout, debemos recordar usar `model.eval()` para asegurarnos de que el dropout esté \"desactivado\" durante la evaluación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8jAUr_ZFvcS"
      },
      "source": [
        "def evaluate_epoch(model, iterator):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    ########################################################################\n",
        "    # TODO: Implementá la función evaluate_epoch() siguiendo las           #\n",
        "    #       instrucciones de arriba teniendo en cuenta las secuencias      #\n",
        "    #       empaquetadas con padding.                                      #\n",
        "    ########################################################################\n",
        "    # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, y in iterator:\n",
        "        text, text_length = x\n",
        "        salida_modelo = model(text, text_length)\n",
        "        perdida = loss(salida_modelo, y)\n",
        "        accuracy = binary_accuracy(salida_modelo, y)\n",
        "        epoch_acc = epoch_acc + accuracy\n",
        "        epoch_loss = epoch_loss + perdida\n",
        "\n",
        "    # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "    ########################################################################\n",
        "    #                          FINAL DE TU CÓDIGO                          #       \n",
        "    ########################################################################\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "645gw3EkFvcT"
      },
      "source": [
        "Y también crea una función bonita para decirnos cuánto tardan en ejecutarse nuestras épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9IGmGPhFvcU"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAxlhV1YFvcU"
      },
      "source": [
        "Finalmente, entrenamos a nuestro modelo..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI5G7wFdFvcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd83077b-b83f-4c76-e709-8fd5b6e03250"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train_epoch(model, train_iterator)\n",
        "    valid_loss, valid_acc = evaluate_epoch(model, valid_iterator)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.671 | Train Acc: 58.33%\n",
            "\t Val. Loss: 0.644 |  Val. Acc: 63.07%\n",
            "Epoch: 02 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.651 | Train Acc: 61.29%\n",
            "\t Val. Loss: 0.586 |  Val. Acc: 68.68%\n",
            "Epoch: 03 | Epoch Time: 0m 38s\n",
            "\tTrain Loss: 0.602 | Train Acc: 66.99%\n",
            "\t Val. Loss: 0.579 |  Val. Acc: 68.82%\n",
            "Epoch: 04 | Epoch Time: 0m 38s\n",
            "\tTrain Loss: 0.581 | Train Acc: 69.44%\n",
            "\t Val. Loss: 0.615 |  Val. Acc: 65.61%\n",
            "Epoch: 05 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.588 | Train Acc: 67.95%\n",
            "\t Val. Loss: 0.548 |  Val. Acc: 72.36%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9UjMvBvFvcW"
      },
      "source": [
        "... ¡y obtenemos nuestra nueva y mejorada precisión de prueba! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhPVRb-1FvcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb23c14-6fce-4398-c74e-d48f2ed012e2"
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate_epoch(model, test_iterator)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.547 | Test Acc: 72.49%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwmOUN6JFvca"
      },
      "source": [
        "# Sección 3 - Predicciones con entrada del usuario\n",
        "\n",
        "Ahora podemos usar nuestro modelo para predecir el sentimiento de cualquier oración que le demos. Como ha sido entrenado en reseñas de películas, las oraciones proporcionadas también deben ser reseñas de películas.\n",
        "\n",
        "Cuando se usa un modelo para la predicción, siempre debe estar en modo de evaluación. Si se sigue este tutorial paso a paso, entonces ya debería estar en modo de evaluación (desde que ejecutamos `evaluate()` en el conjunto de prueba), sin embargo, lo configuramos explícitamente para evitar cualquier riesgo.\n",
        "\n",
        "Nuestra función `predict_sentiment` debe hacer algunas cosas:\n",
        "- configurar el modelo en modo de evaluación\n",
        "- tokenizar la oración, es decir, pasar de una cadena sin procesar a una lista de tokens\n",
        "- indexar los tokens convirtiéndolos en su representación entera de nuestro vocabulario\n",
        "- obtener la longitud de nuestra secuencia\n",
        "- convertir los índices, que son una lista de Python en un tensor de PyTorch\n",
        "- agregar una dimensión de lote al hacer `unsqueeze`\n",
        "- convertir la longitud de la secuencia en un tensor\n",
        "- rescalar la predicción de salida a un rango entre 0 y 1 con la función \"sigmoide\"\n",
        "- convertir el tensor que contiene un valor único en un número entero con el método `item()`\n",
        "\n",
        "Esperamos que las reseñas con un sentimiento negativo devuelvan un valor cercano a 0 y que las reseñas positivas devuelvan un valor cercano a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlYhtEbBHtWL",
        "outputId": "fac4c9b6-b308-4ecc-f2ed-b77774402df4"
      },
      "source": [
        "a=4\n",
        "torch.Tensor([a])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv2gcA03Fvcb"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    ########################################################################\n",
        "    # TODO: Implementá la función predict_sentiment() siguiendo las        #\n",
        "    #       instrucciones de arriba.                                       #\n",
        "    ########################################################################\n",
        "    # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "\n",
        "    model.eval()\n",
        "    oracion_tokens = nlp(sentence)\n",
        "    oracion_tokens = [oracion.text for oracion in oracion_tokens]\n",
        "    \n",
        "    oracion_indices = [TEXT.vocab.stoi[i] for i in oracion_tokens]\n",
        "    \n",
        "    longitud_secuencia = len(oracion_indices)\n",
        "    \n",
        "    tensor = torch.IntTensor(oracion_indices)\n",
        "    \n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    \n",
        "    longitud_tensor = torch.IntTensor([longitud_secuencia])\n",
        "    \n",
        "    salida = model(tensor.to(device), longitud_tensor.to(device))\n",
        "    \n",
        "    salida = torch.sigmoid(salida)\n",
        "    \n",
        "    return salida.item()\n",
        "\n",
        "\n",
        "  \n",
        "    # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n",
        "    ########################################################################\n",
        "    #                          FINAL DE TU CÓDIGO                          #       \n",
        "    ########################################################################"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVHPLLYtFvcd"
      },
      "source": [
        "Un ejemplo de reseña negativa..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1i8avcHFvce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49dc1e61-9a46-41c1-d446-95456defae8c"
      },
      "source": [
        "predict_sentiment(model, \"This film is terrible\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08206340670585632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvBnARZQFvch"
      },
      "source": [
        "Un ejemplo de reseña positiva..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYbCFGuqFvci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850b5634-67fe-4bd5-85b4-41c66e49dd2b"
      },
      "source": [
        "predict_sentiment(model, \"This film is great\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.879744291305542"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    }
  ]
}